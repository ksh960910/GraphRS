reading train and test user-item set ...
building the adj mat ...
loading over ...
start training ...
+-------+-------------------+--------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |      Loss      |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 77.88088631629944 | 263.85864448547363 | 455.7392578125 | [0.01560868 0.03306649 0.04059293] | [0.00725164 0.01095624 0.01232634] | [0.00088101 0.00096115 0.00079083] | [0.01755449 0.03811019 0.04688013] |
|   0   | 77.88088631629944 | 242.02174878120422 | 455.7392578125 | [0.02546975 0.03432154 0.04324156] | [0.01025467 0.01211202 0.01376513] | [0.00152606 0.00102657 0.00086086] | [0.03032428 0.0404954  0.05075318] |
+-------+-------------------+--------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 75.9791s, training loss at epoch 1: 447.0508
using time 75.9187s, training loss at epoch 2: 443.5154
using time 75.9446s, training loss at epoch 3: 440.2235
using time 80.4149s, training loss at epoch 4: 437.3009
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 75.92944359779358 |  267.863707780838  | 434.0646057128906 | [0.02072821 0.03626526 0.0455693 ] | [0.00852809 0.01184729 0.01355252] | [0.00121618 0.00107707 0.00090547] | [0.02405345 0.04242579 0.05325496] |
|   5   | 75.92944359779358 | 252.80133390426636 | 434.0646057128906 | [0.02642341 0.03719675 0.04776265] | [0.01154626 0.01381222 0.01576222] | [0.00159342 0.0011282  0.00096774] | [0.03144302 0.04426131 0.0564966 ] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 75.1707s, training loss at epoch 6: 431.0542
using time 75.5611s, training loss at epoch 7: 428.2856
using time 82.8059s, training loss at epoch 8: 425.5956
using time 75.8425s, training loss at epoch 9: 423.2540
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 75.82222700119019 | 270.04216480255127 | 420.7248840332031 | [0.02393406 0.04031465 0.05023645] | [0.0101702  0.01364016 0.01545868] | [0.00141298 0.00119409 0.00099432] | [0.02789441 0.04697506 0.05844682] |
|   10  | 75.82222700119019 | 240.8631751537323  | 420.7248840332031 | [0.0284901  0.04072554 0.05187215] | [0.01207636 0.01465709 0.01670723] | [0.00171081 0.00122432 0.0010397 ] | [0.03371203 0.04802723 0.06079825] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 76.2458s, training loss at epoch 11: 418.3521
using time 75.9505s, training loss at epoch 12: 416.0203
using time 77.2302s, training loss at epoch 13: 413.6266
using time 75.8993s, training loss at epoch 14: 411.3404
+-------+------------------+--------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)   |      Loss     |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+--------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 75.9834406375885 | 267.24021196365356 | 409.064453125 | [0.02641492 0.04287922 0.05409081] | [0.01152598 0.01500734 0.0170652 ] | [0.00154734 0.00126474 0.00106673] | [0.0305305  0.0497353  0.06270401] |
|   15  | 75.9834406375885 | 255.14517664909363 | 409.064453125 | [0.03068333 0.04529462 0.05647364] | [0.0130508  0.01613163 0.0181918 ] | [0.00181914 0.00134525 0.00112347] | [0.03587073 0.05273068 0.06565927] |
+-------+------------------+--------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 75.3210s, training loss at epoch 16: 406.7859
using time 85.2157s, training loss at epoch 17: 404.3856
using time 75.2716s, training loss at epoch 18: 402.1862
using time 75.4511s, training loss at epoch 19: 399.8258
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 75.3344624042511 | 266.4807376861572  | 397.6188049316406 | [0.02830515 0.04478968 0.05642861] | [0.01249769 0.01598265 0.01811412] | [0.00164263 0.0013133  0.00110494] | [0.0325021  0.05165577 0.06496039] |
|   20  | 75.3344624042511 | 251.33666849136353 | 397.6188049316406 | [0.03341766 0.04929152 0.06147989] | [0.01424485 0.01758993 0.01982727] | [0.00197001 0.00145535 0.00121526] | [0.03885667 0.05705597 0.07112694] |
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 75.5051s, training loss at epoch 21: 394.9789
using time 75.5686s, training loss at epoch 22: 392.7036
using time 75.6609s, training loss at epoch 23: 390.1989
using time 75.6024s, training loss at epoch 24: 387.6172
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 76.17384576797485 | 273.82341265678406 | 385.29449462890625 | [0.02960773 0.04638877 0.05910014] | [0.01308003 0.0166324  0.01895724] | [0.00170251 0.00135127 0.00115071] | [0.03375078 0.05317463 0.0676622 ] |
|   25  | 76.17384576797485 | 255.64977359771729 | 385.29449462890625 | [0.03494084 0.05206223 0.06516175] | [0.01493907 0.01855471 0.02095853] | [0.00205116 0.00153867 0.00128774] | [0.04044025 0.06027039 0.07531829] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 75.3591s, training loss at epoch 26: 382.7943
using time 75.4607s, training loss at epoch 27: 380.2315
using time 76.5840s, training loss at epoch 28: 377.6861
using time 96.1652s, training loss at epoch 29: 375.1184
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 97.45286560058594 | 275.5701606273651 | 372.5728759765625 | [0.03059434 0.04738692 0.06079357] | [0.0134587  0.01700472 0.01945722] | [0.00175545 0.00137427 0.00117991] | [0.03479499 0.05419694 0.06939282] |
|   30  | 97.45286560058594 | 256.1296947002411 | 372.5728759765625 | [0.03641078 0.05459809 0.06866854] | [0.01556858 0.01940097 0.02198256] | [0.00213822 0.0016082  0.00135379] | [0.04211049 0.06295695 0.07917087] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 94.5739s, training loss at epoch 31: 370.2502
using time 91.5042s, training loss at epoch 32: 367.6140
using time 91.7570s, training loss at epoch 33: 364.9955
using time 98.4299s, training loss at epoch 34: 362.5357
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 91.85770344734192 | 291.26923537254333 | 360.0198059082031 | [0.03149928 0.04850297 0.06206428] | [0.01389983 0.0174811  0.01996365] | [0.00180656 0.00140184 0.00120219] | [0.03583921 0.05525576 0.07074373] |
|   35  | 91.85770344734192 | 259.2219307422638  | 360.0198059082031 | [0.03806641 0.05657655 0.07067727] | [0.01617844 0.02007907 0.02266884] | [0.00222488 0.00165921 0.00139055] | [0.04384375 0.06498172 0.08133745] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 92.5283s, training loss at epoch 36: 357.6508
using time 92.7387s, training loss at epoch 37: 355.0882
using time 93.0369s, training loss at epoch 38: 352.6944
using time 93.7224s, training loss at epoch 39: 350.0836
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   40  | 92.42386770248413 | 280.65193271636963 | 347.4747314453125 | [0.03161605 0.0484102  0.06217393] | [0.01391588 0.01745366 0.0199714 ] | [0.00180401 0.00139436 0.00120024] | [0.03575158 0.05497828 0.07068531] |
|   40  | 92.42386770248413 | 253.67562651634216 | 347.4747314453125 | [0.03913456 0.05810902 0.07262764] | [0.01682764 0.02083454 0.02350438] | [0.00228043 0.00170175 0.00142824] | [0.04491523 0.06669923 0.0835907 ] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 75.7388s, training loss at epoch 41: 345.1455
using time 75.7257s, training loss at epoch 42: 342.4561
using time 76.1101s, training loss at epoch 43: 339.9920
using time 76.1938s, training loss at epoch 44: 337.2977
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   45  | 76.20750689506531 | 284.2021310329437  | 334.6413879394531 | [0.03131278 0.04828384 0.06185337] | [0.01393509 0.01751373 0.01999083] | [0.0017821  0.00138742 0.00118831] | [0.03530614 0.05470079 0.07003542] |
|   45  | 76.20750689506531 | 248.23541069030762 | 334.6413879394531 | [0.03963134 0.05908483 0.07464011] | [0.01709515 0.02120566 0.02405161] | [0.00230288 0.00173228 0.00146382] | [0.04535642 0.06789676 0.08566274] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 75.3025s, training loss at epoch 46: 332.1698
using time 75.3691s, training loss at epoch 47: 329.7286
using time 75.5600s, training loss at epoch 48: 326.9633
using time 80.0376s, training loss at epoch 49: 324.5711
+-------+------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   50  | 75.5240306854248 |  280.551429271698  | 321.87774658203125 | [0.03140793 0.04845055 0.06196884] | [0.01402298 0.01761124 0.02007209] | [0.00178356 0.00138961 0.00118782] | [0.03535726 0.05482493 0.07004272] |
|   50  | 75.5240306854248 | 252.86019158363342 | 321.87774658203125 | [0.04010085 0.05984172 0.07592504] | [0.01740236 0.02158131 0.02452911] | [0.00232691 0.00175375 0.0014889 ] | [0.04582913 0.06876339 0.08708874] |
+-------+------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 75.4809s, training loss at epoch 51: 319.2456
using time 75.3842s, training loss at epoch 52: 316.6958
using time 75.4536s, training loss at epoch 53: 314.1274
using time 75.5668s, training loss at epoch 54: 311.6041
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   55  | 75.53693318367004 | 260.36167001724243 | 308.8895263671875 | [0.0318446  0.04863626 0.06255128] | [0.01419919 0.01772661 0.02026296] | [0.00180255 0.00138815 0.00119574] | [0.03575158 0.05478842 0.07050276] |
|   55  | 75.53693318367004 | 245.0980887413025  | 308.8895263671875 | [0.04045022 0.06100219 0.07646505] | [0.01758432 0.02192013 0.02476105] | [0.00234818 0.0017831  0.00149875] | [0.0462073  0.06992153 0.08769539] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 77.2497s, training loss at epoch 56: 306.4041
using time 77.3315s, training loss at epoch 57: 303.7976
using time 75.8339s, training loss at epoch 58: 301.3722
using time 75.6300s, training loss at epoch 59: 298.6893
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   60  | 78.27361822128296 |  273.847736120224 | 296.15338134765625 | [0.03200217 0.0483287  0.06225583] | [0.01419111 0.01762303 0.02015985] | [0.00180803 0.0013803  0.00118929] | [0.03587572 0.05446712 0.07012304] |
|   60  | 78.27361822128296 | 252.7952287197113 | 296.15338134765625 | [0.0408871  0.06138387 0.07727451] | [0.0178009  0.02212539 0.02503634] | [0.00237654 0.00179472 0.00151096] | [0.04677455 0.07032333 0.08841233] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 76.5574s, training loss at epoch 61: 293.7047
using time 79.2828s, training loss at epoch 62: 290.9981
using time 82.5503s, training loss at epoch 63: 288.3351
using time 79.6564s, training loss at epoch 64: 286.0440
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   65  | 79.36625075340271 | 269.24441480636597 | 283.44256591796875 | [0.03169001 0.04805566 0.0619801 ] | [0.01398565 0.01742626 0.01996399] | [0.00178977 0.00137081 0.00118308] | [0.0355033  0.05409471 0.06975793] |
|   65  | 79.36625075340271 | 252.63130927085876 | 283.44256591796875 | [0.04137486 0.06230195 0.07781209] | [0.01792455 0.02233759 0.02518447] | [0.00239742 0.00181619 0.00152212] | [0.04719211 0.07118997 0.08899534] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 75.4579s, training loss at epoch 66: 280.8243
using time 75.3516s, training loss at epoch 67: 278.4248
using time 75.9543s, training loss at epoch 68: 275.9750
using time 76.0008s, training loss at epoch 69: 273.1455
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   70  | 76.03149700164795 | 268.31794333457947 | 270.8446044921875 | [0.03179554 0.04819357 0.06192481] | [0.01405044 0.01749483 0.01999889] | [0.00179525 0.00137446 0.00118113] | [0.03560554 0.05425536 0.06963379] |
|   70  | 76.03149700164795 | 249.7876307964325  | 270.8446044921875 | [0.04114182 0.06216646 0.07797747] | [0.01782606 0.0222639  0.02516581] | [0.00237773 0.00181126 0.00152396] | [0.04685333 0.07095361 0.08908988] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 75.2919s, training loss at epoch 71: 268.3781
using time 75.5599s, training loss at epoch 72: 265.6297
using time 75.7686s, training loss at epoch 73: 263.4353
using time 77.4517s, training loss at epoch 74: 260.8979
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   75  | 75.91919255256653 | 273.21711707115173 | 258.3934326171875 | [0.03141799 0.04822418 0.06168848] | [0.01389378 0.01742334 0.01988329] | [0.00176859 0.00136953 0.00117407] | [0.03508708 0.05413852 0.06924678] |
|   75  | 75.91919255256653 | 248.98528289794922 | 258.3934326171875 | [0.04169846 0.0625167  0.07863682] | [0.01800652 0.02240668 0.02536755] | [0.00240609 0.00182151 0.00153644] | [0.04741271 0.07130814 0.08983046] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 78.8607s, training loss at epoch 76: 256.0657
using time 77.5328s, training loss at epoch 77: 253.6531
using time 75.4022s, training loss at epoch 78: 251.1396
using time 76.1129s, training loss at epoch 79: 248.7670
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   80  | 84.19099402427673 | 267.70042848587036 | 246.34884643554688 | [0.03139682 0.04842775 0.06176501] | [0.01385658 0.01742962 0.01986061] | [0.00177151 0.0013761  0.00117492] | [0.03510899 0.0543868  0.0693125 ] |
|   80  | 84.19099402427673 | 246.82207870483398 | 246.34884643554688 | [0.04202476 0.06282038 0.07896216] | [0.01813648 0.02252982 0.02549723] | [0.00242066 0.00182741 0.00154326] | [0.04769633 0.07155238 0.09017711] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 78.7574s, training loss at epoch 81: 244.0902
using time 82.6424s, training loss at epoch 82: 241.9334
using time 79.3052s, training loss at epoch 83: 239.4109
using time 84.8412s, training loss at epoch 84: 237.0657
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   85  | 76.1539855003357 | 268.82826948165894 | 234.8933868408203 | [0.03122755 0.0482195  0.06108636] | [0.01371473 0.01727561 0.01962224] | [0.00175764 0.00136606 0.00115983] | [0.03486801 0.05397787 0.06847274] |
|   85  | 76.1539855003357 | 242.78576636314392 | 234.8933868408203 | [0.04225314 0.06282359 0.07864881] | [0.0182283  0.02257676 0.02548225] | [0.00243248 0.00182978 0.00153591] | [0.04795632 0.0716548  0.08974379] |
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 80.0958s, training loss at epoch 86: 232.4834
using time 75.7529s, training loss at epoch 87: 230.5199
using time 75.8107s, training loss at epoch 88: 227.9240
using time 75.6755s, training loss at epoch 89: 225.6722
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   90  | 75.93045544624329 | 273.9473526477814 | 223.6837158203125 | [0.03076843 0.04778243 0.06062186] | [0.01345751 0.01702119 0.01936205] | [0.00172953 0.00135145 0.00114864] | [0.03429844 0.05337909 0.06783015] |
|   90  | 75.93045544624329 | 251.1215784549713 | 223.6837158203125 | [0.04249209 0.06312654 0.07934107] | [0.0183447  0.02270943 0.02568066] | [0.00244627 0.00183943 0.00154865] | [0.0481848  0.07196206 0.09050013] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 76.5645s, training loss at epoch 91: 221.4156
using time 75.6266s, training loss at epoch 92: 219.3146
using time 87.1469s, training loss at epoch 93: 217.1491
using time 75.7231s, training loss at epoch 94: 215.1046
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   95  | 75.69429659843445 | 272.94699120521545 | 212.94134521484375 | [0.03078136 0.04747078 0.0606404 ] | [0.01341398 0.01691779 0.01930863] | [0.00173026 0.00134689 0.00114815] | [0.03432035 0.05316003 0.06780824] |
|   95  | 75.69429659843445 | 249.31673097610474 | 212.94134521484375 | [0.04208378 0.06315948 0.07951578] | [0.01815871 0.02261743 0.02561724] | [0.00241751 0.00183608 0.00155167] | [0.04760179 0.07190691 0.09070497] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 75.3329s, training loss at epoch 96: 210.8624
using time 75.3003s, training loss at epoch 97: 208.7586
using time 75.3120s, training loss at epoch 98: 206.7184
using time 75.2374s, training loss at epoch 99: 204.7859
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  100  | 77.23602843284607 | 271.35802364349365 | 203.06304931640625 | [0.03049436 0.04718831 0.06018208] | [0.01336202 0.0168685  0.01923576] | [0.00171091 0.00133612 0.00113963] | [0.03392603 0.0527511  0.0673336 ] |
|  100  | 77.23602843284607 | 246.1419460773468  | 203.06304931640625 | [0.04216225 0.06307352 0.07962429] | [0.01819089 0.02261202 0.02564637] | [0.00242027 0.00183431 0.00155351] | [0.04760179 0.07185964 0.09081527] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 75.3247s, training loss at epoch 101: 200.8199
using time 76.4925s, training loss at epoch 102: 198.9288
using time 75.5283s, training loss at epoch 103: 196.9590
using time 75.4481s, training loss at epoch 104: 194.7746
+-------+------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  105  | 80.3867814540863 | 277.8666296005249  | 193.25599670410156 | [0.03037909 0.04684631 0.0596557 ] | [0.0132323  0.01668345 0.01901425] | [0.00170506 0.0013248  0.00112722] | [0.03377998 0.05229837 0.06661799] |
|  105  | 80.3867814540863 | 241.84193396568298 | 193.25599670410156 | [0.04214696 0.06312191 0.07960802] | [0.01815725 0.02259569 0.02561508] | [0.00242027 0.00183746 0.00155167] | [0.04760967 0.07191479 0.09071285] |
+-------+------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 75.7666s, training loss at epoch 106: 191.1797
using time 75.4217s, training loss at epoch 107: 189.3801
using time 75.3276s, training loss at epoch 108: 187.7098
using time 75.4607s, training loss at epoch 109: 185.7889
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  110  | 75.29254364967346 | 283.5354161262512  | 183.99615478515625 | [0.03017712 0.04653315 0.05935066] | [0.01312388 0.01655885 0.01889393] | [0.00169119 0.00131494 0.00112162] | [0.03353171 0.05191865 0.06628208] |
|  110  | 75.29254364967346 | 248.44569087028503 | 183.99615478515625 | [0.04209735 0.06305822 0.07940607] | [0.0181587  0.0225907  0.02558707] | [0.00241712 0.00183608 0.00154878] | [0.04753876 0.07182812 0.09053952] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 75.4094s, training loss at epoch 111: 182.5056
using time 75.8480s, training loss at epoch 112: 180.5997
using time 75.4017s, training loss at epoch 113: 179.2021
using time 75.5120s, training loss at epoch 114: 177.3736
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  115  | 77.26720976829529 | 273.2340478897095  | 175.81036376953125 | [0.03014936 0.04614173 0.05869758] | [0.01299718 0.01635322 0.01864173] | [0.00168717 0.00130143 0.00110762] | [0.03346599 0.0514221  0.06547154] |
|  115  | 77.26720976829529 | 250.99979853630066 | 175.81036376953125 | [0.04203055 0.06284081 0.07916242] | [0.01811277 0.02250826 0.02550316] | [0.00240648 0.00182623 0.00154248] | [0.04735756 0.07149723 0.09019287] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 75.6448s, training loss at epoch 116: 174.1754
using time 75.3136s, training loss at epoch 117: 172.6485
using time 75.4474s, training loss at epoch 118: 170.9099
using time 75.2559s, training loss at epoch 119: 169.5057
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|  120  | 75.36742305755615 | 264.0857775211334 | 167.82489013671875 | [0.03006807 0.04606844 0.05837753] | [0.01299717 0.01635073 0.01859353] | [0.00168352 0.0012987  0.00110251] | [0.03337106 0.05130527 0.06515024] |
|  120  | 75.36742305755615 | 243.8357071876526 | 167.82489013671875 | [0.04171292 0.06247829 0.07874289] | [0.01802942 0.02241526 0.02539911] | [0.00238679 0.00181363 0.00153289] | [0.04700303 0.07102452 0.08957834] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 76.2866s, training loss at epoch 121: 166.5259
using time 75.6746s, training loss at epoch 122: 165.1114
using time 75.6106s, training loss at epoch 123: 163.6741
using time 75.6269s, training loss at epoch 124: 162.2034
Process ForkPoolWorker-1242:
Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 131, in worker
    put((job, i, result))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 136, in worker
    put((job, i, (False, wrapped)))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Process ForkPoolWorker-1244:
Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 131, in worker
    put((job, i, result))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 136, in worker
    put((job, i, (False, wrapped)))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Process ForkPoolWorker-1239:
Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 131, in worker
    put((job, i, result))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 136, in worker
    put((job, i, (False, wrapped)))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Process ForkPoolWorker-1229:
Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 131, in worker
    put((job, i, result))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 136, in worker
    put((job, i, (False, wrapped)))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Process ForkPoolWorker-1227:
Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 131, in worker
    put((job, i, result))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 136, in worker
    put((job, i, (False, wrapped)))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Process ForkPoolWorker-1233:
Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 131, in worker
    put((job, i, result))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 136, in worker
    put((job, i, (False, wrapped)))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Process ForkPoolWorker-1241:
Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 131, in worker
    put((job, i, result))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 136, in worker
    put((job, i, (False, wrapped)))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Process ForkPoolWorker-1226:
Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 131, in worker
    put((job, i, result))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 136, in worker
    put((job, i, (False, wrapped)))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Process ForkPoolWorker-1236:
Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 131, in worker
    put((job, i, result))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 136, in worker
    put((job, i, (False, wrapped)))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Process ForkPoolWorker-1235:
Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 131, in worker
    put((job, i, result))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 136, in worker
    put((job, i, (False, wrapped)))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Process ForkPoolWorker-1240:
Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 131, in worker
    put((job, i, result))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/pool.py", line 136, in worker
    put((job, i, (False, wrapped)))
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/queues.py", line 368, in put
    self._writer.send_bytes(obj)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/wxy/anaconda3/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
