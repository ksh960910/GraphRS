reading train and test user-item set ...
building the adj mat ...
loading over ...
Method 4 GCL model setup
Support view 2개의 max값
start training ...
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 117.38294339179993 | 63.71778082847595 | 573.7129516601562 | [0.1319951  0.18756071 0.2266051 ] | [0.1038979  0.12210481 0.13378414] | [0.03824771 0.02766511 0.02247248] | [0.42692076 0.52270748 0.57914127] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 117.5923s, training loss at epoch 1: 532.4651
using time 118.0639s, training loss at epoch 2: 519.5935
using time 113.4616s, training loss at epoch 3: 507.4992
using time 114.1803s, training loss at epoch 4: 492.2825
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 113.53650617599487 | 67.19303846359253 | 470.22711181640625 | [0.13530732 0.19049808 0.22818399] | [0.10980175 0.12753282 0.13877725] | [0.03903979 0.02780662 0.02247304] | [0.42534664 0.51078438 0.55777346] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 128.2082s, training loss at epoch 6: 442.3307
using time 112.4650s, training loss at epoch 7: 414.7252
using time 113.2422s, training loss at epoch 8: 390.7012
using time 113.3483s, training loss at epoch 9: 370.4891
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 114.64945077896118 | 67.40319752693176 | 353.8443298339844 | [0.18146104 0.25297953 0.30303695] | [0.15255415 0.17517507 0.19011116] | [0.05603021 0.03958822 0.03185802] | [0.57914127 0.68172684 0.73481144] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 112.7251s, training loss at epoch 11: 340.4357
using time 112.0011s, training loss at epoch 12: 329.5943
using time 114.7158s, training loss at epoch 13: 320.8319
using time 113.6715s, training loss at epoch 14: 313.8332
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 112.88321828842163 | 66.38886094093323 | 307.88726806640625 | [0.18590386 0.25831138 0.30932695] | [0.15653106 0.17939361 0.19459565] | [0.0577316  0.04065828 0.03267075] | [0.5905285  0.69127202 0.74750486] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 113.8865s, training loss at epoch 16: 302.9885
using time 113.9143s, training loss at epoch 17: 298.7000
using time 112.6982s, training loss at epoch 18: 295.1486
using time 113.0598s, training loss at epoch 19: 292.0890
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 112.07625246047974 | 65.93854808807373 | 289.34063720703125 | [0.18529663 0.25759641 0.3065146 ] | [0.15597434 0.17874233 0.19339169] | [0.05751892 0.04041547 0.03238216] | [0.5897247  0.69170742 0.74365329] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 112.7970s, training loss at epoch 21: 287.0659
using time 112.1864s, training loss at epoch 22: 284.7978
using time 111.6549s, training loss at epoch 23: 283.0887
using time 112.4536s, training loss at epoch 24: 281.4077
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 112.08618950843811 | 65.48344707489014 | 279.8156433105469 | [0.18282514 0.25416477 0.30113804] | [0.15389942 0.17645586 0.1904887 ] | [0.05655436 0.03983355 0.03173912] | [0.58550472 0.68752093 0.74003617] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 2 log:0.182825141059337
early stopping at 25, recall@20:0.1859
