nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 3 --context_hops 3 --pool mean --ns mixgcf --n_negs 128 --K 1 &
cl loss 분모에 final layer의 z'과 final layer의 z(perturb x)의 mixing을 더해줬을때의 실험결과
reading train and test user-item set ...
building the adj mat ...
loading over ...
X Mix Simple GCL model setup
start training ...
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 212.4097764492035 | 50.95156407356262 | 712.2655029296875 | [0.12318673 0.17566913 0.21392851] | [0.0994722  0.11642652 0.12785016] | [0.64446508 0.66417066 0.6751391 ] | [0.03688459 0.02656491 0.02169938] | [0.4111126  0.50435394 0.56329962] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 213.9662s, training loss at epoch 1: 640.8563
using time 218.4071s, training loss at epoch 2: 614.7695
using time 218.1034s, training loss at epoch 3: 593.2120
using time 220.1727s, training loss at epoch 4: 571.0507
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 219.77108788490295 | 57.658029317855835 | 547.8060302734375 | [0.15717517 0.22066614 0.26520578] | [0.12925729 0.14959168 0.16293249] | [0.60869735 0.63222071 0.64578596] | [0.04765557 0.03393814 0.02744546] | [0.51172215 0.60958537 0.66427758] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 222.3398s, training loss at epoch 6: 524.9824
using time 214.6419s, training loss at epoch 7: 503.3492
using time 213.8895s, training loss at epoch 8: 484.3483
using time 215.8153s, training loss at epoch 9: 468.2260
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 224.1922206878662 | 63.82153844833374 | 455.0481262207031 | [0.1778389  0.24909127 0.29918564] | [0.14919946 0.17176619 0.18673278] | [0.58751815 0.61187287 0.62599589] | [0.05533525 0.03924241 0.03165204] | [0.57133766 0.67248309 0.72931878] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 215.0793s, training loss at epoch 11: 444.3020
using time 213.7318s, training loss at epoch 12: 435.7024
using time 213.1800s, training loss at epoch 13: 428.3183
using time 212.1022s, training loss at epoch 14: 422.4333
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 229.32790565490723 | 62.53457832336426 | 417.24176025390625 | [0.18118339 0.25272224 0.3032112 ] | [0.15211577 0.17471217 0.18978958] | [0.59109202 0.61422797 0.62745417] | [0.05644216 0.03979252 0.03205785] | [0.5782035  0.67767433 0.73487842] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 214.1822s, training loss at epoch 16: 412.7818
using time 210.7566s, training loss at epoch 17: 409.0060
using time 213.6898s, training loss at epoch 18: 405.6059
using time 206.6843s, training loss at epoch 19: 402.9207
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 224.47423720359802 | 64.11304950714111 | 400.1754150390625 | [0.18179447 0.25236986 0.30221439] | [0.15212426 0.17435554 0.18923474] | [0.59373936 0.61567837 0.62794248] | [0.05656608 0.03968032 0.03190881] | [0.57910778 0.67727242 0.73283542] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 217.9020s, training loss at epoch 21: 398.0193
using time 212.8332s, training loss at epoch 22: 395.9257
using time 209.0252s, training loss at epoch 23: 394.1963
using time 217.3468s, training loss at epoch 24: 392.4414
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 228.54871106147766 | 68.90967082977295 | 390.9906311035156 | [0.18020575 0.25036156 0.29849828] | [0.15047019 0.17265523 0.18708409] | [0.59583945 0.61658701 0.62795244] | [0.05594815 0.03936047 0.03157389] | [0.57495479 0.67368879 0.72874941] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 219.6122s, training loss at epoch 26: 389.5253
using time 216.2419s, training loss at epoch 27: 388.2523
using time 214.6970s, training loss at epoch 28: 387.1656
using time 211.6230s, training loss at epoch 29: 386.0670
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 224.1456208229065 | 49.58151149749756 | 385.02313232421875 | [0.17836993 0.24688836 0.29401391] | [0.14882296 0.1704979  0.18463976] | [0.5965752  0.61625035 0.62689671] | [0.05538047 0.03885726 0.03114408] | [0.56949561 0.66742582 0.72282135] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 216.2756s, training loss at epoch 31: 384.1342
using time 207.4464s, training loss at epoch 32: 383.2039
using time 218.8508s, training loss at epoch 33: 382.3999
using time 215.6494s, training loss at epoch 34: 381.6425
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 219.65206289291382 | 49.92385149002075 | 380.8326721191406 | [0.17551344 0.24296524 0.28879455] | [0.14661729 0.16799477 0.18173263] | [0.59706422 0.61574919 0.62586813] | [0.054508   0.0382544  0.03059147] | [0.56346708 0.66045951 0.71541965] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.17551343933071686
early stopping at 35, recall@20:0.1818
