nohup python main.py --dataset gowalla --gnn mgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 0 --context_hops 3 --pool mean --ns mixgcf --n_negs 64 --K 1 --tau 0.2 --lamb 0.5 --eps 0.1 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
start training ...
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 1580.0799260139465 | 41.325167655944824 | 2064.743896484375 | [0.12810448 0.18160016 0.22031096] | [0.10722632 0.12424542 0.13593124] | [0.54280346 0.57035562 0.58775835] | [0.04041295 0.02901986 0.02369717] | [0.47437873 0.58041396 0.63989551] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 1560.1259s, training loss at epoch 1: 1929.4194
using time 1552.2163s, training loss at epoch 2: 1883.5081
using time 1551.3384s, training loss at epoch 3: 1851.3333
using time 1554.1845s, training loss at epoch 4: 1823.8519
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 1552.5913331508636 | 37.713951110839844 | 1795.9500732421875 | [0.14202622 0.19958949 0.24196554] | [0.12055915 0.13874452 0.15145161] | [0.54261631 0.57046184 0.58814503] | [0.04524081 0.03224429 0.02624032] | [0.50964566 0.61474312 0.6728515 ] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 1551.8839s, training loss at epoch 6: 1768.9067
using time 1551.4497s, training loss at epoch 7: 1742.7499
using time 1553.8326s, training loss at epoch 8: 1719.4463
using time 1550.7938s, training loss at epoch 9: 1698.8536
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 1553.3253173828125 | 38.15283751487732 | 1681.172119140625 | [0.14785155 0.20736252 0.25089189] | [0.12596352 0.14468892 0.15769777] | [0.53975784 0.56813424 0.5860059 ] | [0.04710463 0.03349186 0.02717585] | [0.52451604 0.62978096 0.68778887] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 1551.8460s, training loss at epoch 11: 1666.0140
using time 1548.9793s, training loss at epoch 12: 1653.3944
using time 1552.0826s, training loss at epoch 13: 1642.2947
using time 1551.8708s, training loss at epoch 14: 1632.5671
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 1554.0067660808563 | 37.58693742752075 | 1623.9344482421875 | [0.15217085 0.21309837 0.25817149] | [0.13010689 0.14926691 0.16270827] | [0.54367256 0.57203629 0.58988837] | [0.04846775 0.03438609 0.02789258] | [0.53335789 0.63822091 0.69699913] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 1549.4946s, training loss at epoch 16: 1616.5017
using time 1550.8666s, training loss at epoch 17: 1609.8258
using time 1548.4760s, training loss at epoch 18: 1603.8031
using time 1550.6917s, training loss at epoch 19: 1598.3435
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 1549.9475026130676 | 37.92410159111023 | 1593.466552734375 | [0.15466188 0.21708659 0.26265011] | [0.13239875 0.15196389 0.16558146] | [0.54774086 0.57600045 0.59379645] | [0.04928495 0.0349429  0.02834863] | [0.53891754 0.64307723 0.70239132] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 1549.9255s, training loss at epoch 21: 1589.4326
using time 1554.1240s, training loss at epoch 22: 1584.4532
using time 1577.5863s, training loss at epoch 23: 1581.0396
using time 1619.5513s, training loss at epoch 24: 1577.5735
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 1620.161890745163 | 39.102362871170044 | 1574.2945556640625 | [0.15596749 0.21980505 0.26608647] | [0.13353849 0.15350956 0.16735249] | [0.55160231 0.57968904 0.59731312] | [0.0497036  0.03528368 0.02865396] | [0.54052515 0.64635943 0.70527162] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 1612.0368s, training loss at epoch 26: 1571.1018
using time 1615.7094s, training loss at epoch 27: 1568.6411
using time 1616.2448s, training loss at epoch 28: 1565.7994
using time 1618.4944s, training loss at epoch 29: 1563.1289
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 1611.9478859901428 | 39.52668118476868 | 1560.9373779296875 | [0.15697137 0.22053314 0.26778706] | [0.134073   0.15402435 0.16812006] | [0.55463202 0.58241957 0.59998368] | [0.04992799 0.03542853 0.02880914] | [0.54226673 0.64645991 0.70731462] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 1621.6795s, training loss at epoch 31: 1558.5020
using time 1642.1237s, training loss at epoch 32: 1556.4600
using time 1620.3798s, training loss at epoch 33: 1554.2175
using time 1616.7091s, training loss at epoch 34: 1552.3662
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 1616.813839673996 | 40.047587394714355 | 1550.7200927734375 | [0.15776971 0.22112926 0.26848135] | [0.13455427 0.15440193 0.16850668] | [0.55712163 0.58483162 0.60221651] | [0.05013062 0.0354796  0.02882812] | [0.54414227 0.64763213 0.70758256] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 1621.9562s, training loss at epoch 36: 1548.7257
using time 1634.9377s, training loss at epoch 37: 1546.9518
using time 1631.7705s, training loss at epoch 38: 1544.9969
using time 1635.4230s, training loss at epoch 39: 1543.5132
