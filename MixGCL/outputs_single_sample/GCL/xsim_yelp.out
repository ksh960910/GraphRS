nohup python main.py --dataset yelp2018 --gnn gcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 0 --context_hops 3 --pool mean --ns mixgcf --K 1 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
start training ...
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 26.50066566467285 | 39.669923067092896 | 924.5507202148438 | [0.05790037 0.09444641 0.12368687] | [0.04794188 0.0617305  0.07196891] | [0.57294324 0.58926501 0.59982965] | [0.02586681 0.02133463 0.01878658] | [0.34789062 0.47903246 0.55595554] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 25.2977s, training loss at epoch 1: 829.3651
using time 25.1478s, training loss at epoch 2: 796.5837
using time 25.1544s, training loss at epoch 3: 768.2145
using time 25.1784s, training loss at epoch 4: 735.7304
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 25.200113534927368 | 38.922914266586304 | 696.9273681640625 | [0.06891825 0.11217783 0.14652499] | [0.05699815 0.07331285 0.08531147] | [0.5277459  0.54479596 0.55585494] | [0.03109132 0.02562366 0.02242537] | [0.40949855 0.5540293  0.63546798] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 25.2614s, training loss at epoch 6: 650.9491
using time 25.9032s, training loss at epoch 7: 606.5822
using time 25.4906s, training loss at epoch 8: 573.2135
using time 25.8141s, training loss at epoch 9: 549.4829
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 25.719646692276  | 39.23342561721802 | 532.0703735351562 | [0.07274036 0.11900535 0.15554541] | [0.05979122 0.0771833  0.08992839] | [0.5171179  0.53314397 0.54349122] | [0.03270336 0.02699176 0.02367058] | [0.42879247 0.57821776 0.66300366] |
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 25.5885s, training loss at epoch 11: 518.9279
using time 25.7090s, training loss at epoch 12: 508.5627
using time 25.7258s, training loss at epoch 13: 500.4056
using time 25.4931s, training loss at epoch 14: 493.5022
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss      |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 25.560694217681885 | 39.56315803527832 | 487.99169921875 | [0.07280825 0.11876931 0.1551247 ] | [0.05987926 0.07716822 0.08985388] | [0.52124283 0.53687788 0.54686115] | [0.03270652 0.02694518 0.02362006] | [0.42721359 0.57723885 0.66170898] |
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 25.3240s, training loss at epoch 16: 482.8733
using time 25.5621s, training loss at epoch 17: 478.7602
using time 25.3095s, training loss at epoch 18: 475.2044
using time 25.3305s, training loss at epoch 19: 471.9727
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 25.356776475906372 | 39.35468602180481 | 469.21368408203125 | [0.07242447 0.11822999 0.15380609] | [0.05955569 0.07675885 0.0892128 ] | [0.52301096 0.53828838 0.54803282] | [0.0325581  0.02680308 0.02345322] | [0.42601364 0.57515473 0.65817229] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 25.8167s, training loss at epoch 21: 466.3974
using time 25.9313s, training loss at epoch 22: 464.0527
using time 25.9864s, training loss at epoch 23: 461.9228
using time 26.1649s, training loss at epoch 24: 459.6364
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 26.192171096801758 | 39.904688596725464 | 458.01373291015625 | [0.07190828 0.11692833 0.15238172] | [0.05918186 0.07608586 0.08850588] | [0.52418031 0.53913703 0.54868873] | [0.03231022 0.02651573 0.02325534] | [0.42269799 0.57164961 0.65507768] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 25.8014s, training loss at epoch 26: 456.5571
using time 25.5998s, training loss at epoch 27: 454.8928
using time 25.2476s, training loss at epoch 28: 453.3218
using time 25.3154s, training loss at epoch 29: 452.0395
+-------+--------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |       Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 25.684328079223633 | 39.386807441711426 | 450.649658203125 | [0.07133045 0.11517907 0.15031516] | [0.0587473  0.07520095 0.08752102] | [0.52446195 0.53910216 0.54840096] | [0.03208444 0.02615811 0.02297219] | [0.42061387 0.56678666 0.65056208] |
+-------+--------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.07133045323403783
early stopping at 30, recall@20:0.0728
