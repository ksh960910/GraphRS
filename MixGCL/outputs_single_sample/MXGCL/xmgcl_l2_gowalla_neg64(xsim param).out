nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 3 --context_hops 3 --pool mean --ns mixgcf --n_negs 64 --K 1 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
start training ...
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 118.82257843017578 | 52.274487018585205 | 549.4600219726562 | [0.13318305 0.18649854 0.22451271] | [0.1085033  0.12571698 0.13718447] | [0.64613106 0.66405183 0.67382755] | [0.0403242  0.02865982 0.02324838] | [0.44557573 0.53767834 0.59240405] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 117.2500s, training loss at epoch 1: 502.3739
using time 116.5739s, training loss at epoch 2: 481.7602
using time 128.2244s, training loss at epoch 3: 462.4144
using time 117.4759s, training loss at epoch 4: 441.7405
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 116.05502796173096 | 51.17905640602112 | 419.0675048828125 | [0.15968664 0.22489325 0.26976576] | [0.13191811 0.15280244 0.16623454] | [0.61350476 0.63628463 0.64902927] | [0.04853641 0.03462389 0.02795287] | [0.51657847 0.61702056 0.67137786] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 120.0471s, training loss at epoch 6: 396.0313
using time 118.6208s, training loss at epoch 7: 374.8047
using time 127.4935s, training loss at epoch 8: 356.8336
using time 118.2405s, training loss at epoch 9: 341.0128
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 119.91052842140198 | 50.15966510772705 | 328.0254211425781 | [0.1778091  0.2492525  0.29835556] | [0.14845831 0.17106895 0.18575409] | [0.59528601 0.61911952 0.63274605] | [0.05503383 0.03901467 0.03138132] | [0.56648135 0.67100944 0.72751022] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 119.5078s, training loss at epoch 11: 317.4308
using time 117.2745s, training loss at epoch 12: 308.4821
using time 128.3662s, training loss at epoch 13: 301.1487
using time 120.4468s, training loss at epoch 14: 295.0408
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 119.15952062606812 | 53.785075426101685 | 289.6166687011719 | [0.18029422 0.25212047 0.30159725] | [0.15064858 0.17344929 0.18821921] | [0.59694287 0.61966044 0.63244257] | [0.05580749 0.03953212 0.03176759] | [0.57341416 0.67589926 0.73189765] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 118.2858s, training loss at epoch 16: 285.0775
using time 116.8592s, training loss at epoch 17: 281.3484
using time 129.1205s, training loss at epoch 18: 277.8008
using time 120.4655s, training loss at epoch 19: 274.7821
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 116.2544584274292 | 57.752135276794434 | 272.0304870605469 | [0.18056023 0.25130843 0.30028227] | [0.15070701 0.17312507 0.18779105] | [0.59848312 0.62024987 0.63226   ] | [0.05584266 0.03936717 0.03163753] | [0.57502177 0.67432514 0.73022306] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 117.1987s, training loss at epoch 21: 269.7203
using time 118.0613s, training loss at epoch 22: 267.6103
using time 126.8973s, training loss at epoch 23: 265.7431
using time 120.5856s, training loss at epoch 24: 263.9917
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 118.9898772239685 | 56.38116955757141 | 262.5067138671875 | [0.17926932 0.2495166  0.29665556] | [0.1495369  0.17179121 0.18592323] | [0.59980445 0.62060304 0.63202001] | [0.05535367 0.03902304 0.03124121] | [0.57190703 0.67188023 0.72536674] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 116.4817s, training loss at epoch 26: 260.9193
using time 117.5813s, training loss at epoch 27: 259.6385
using time 125.6967s, training loss at epoch 28: 258.4119
using time 114.1301s, training loss at epoch 29: 257.2578
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 115.39871954917908 | 50.67942261695862 | 256.2781066894531 | [0.17750507 0.24637281 0.2929553 ] | [0.14827516 0.17007323 0.18400522] | [0.60018727 0.62016122 0.63111492] | [0.05484125 0.03853322 0.03081865] | [0.56892625 0.66735883 0.72101279] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 115.2346s, training loss at epoch 31: 255.3099
using time 113.6209s, training loss at epoch 32: 254.4145
using time 115.2566s, training loss at epoch 33: 253.3954
using time 117.7761s, training loss at epoch 34: 252.7446
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 114.67984294891357 | 57.27421474456787 | 251.98202514648438 | [0.17567688 0.24349524 0.28851335] | [0.14677569 0.16823103 0.18167794] | [0.60047526 0.61980269 0.63032316] | [0.05428193 0.03808192 0.03036819] | [0.56373501 0.66387568 0.71665885] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.17567688288615083
early stopping at 35, recall@20:0.1806
