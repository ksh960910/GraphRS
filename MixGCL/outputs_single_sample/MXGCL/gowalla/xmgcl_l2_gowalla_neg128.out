nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 2 --context_hops 3 --pool mean --ns mixgcf --n_negs 128 --K 1 --cll 2 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
start training ...
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 209.78506779670715 | 59.23706865310669 | 551.812255859375 | [0.13268503 0.18641369 0.22387204] | [0.10866911 0.12604509 0.13734007] | [0.64737494 0.66460906 0.67378966] | [0.03986201 0.02838603 0.02298044] | [0.44102083 0.53680756 0.59280595] |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 201.6489s, training loss at epoch 1: 504.2236
using time 196.4115s, training loss at epoch 2: 484.5452
using time 202.8620s, training loss at epoch 3: 466.4737
using time 205.1494s, training loss at epoch 4: 447.8083
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 194.3995020389557 | 55.93653893470764 | 426.7104187011719 | [0.15951909 0.22319604 0.26714555] | [0.13177508 0.15214582 0.16533459] | [0.6149696  0.63707925 0.64942716] | [0.04846272 0.03433669 0.02767321] | [0.51379865 0.61246567 0.66611963] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 196.7204s, training loss at epoch 6: 404.7749
using time 207.1665s, training loss at epoch 7: 383.2541
using time 200.1248s, training loss at epoch 8: 364.1485
using time 198.0930s, training loss at epoch 9: 347.6230
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 202.21069645881653 | 54.07331299781799 | 333.8457946777344 | [0.17832133 0.2504091  0.29958331] | [0.14911464 0.17201408 0.18668643] | [0.59426297 0.61803795 0.631538  ] | [0.05521301 0.03920139 0.031479  ] | [0.56705071 0.67258356 0.72724228] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 201.4146s, training loss at epoch 11: 322.4781
using time 205.1638s, training loss at epoch 12: 313.0307
using time 216.6273s, training loss at epoch 13: 304.9818
using time 210.1270s, training loss at epoch 14: 298.4194
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 210.83081531524658 | 58.52138328552246 | 292.73834228515625 | [0.18084341 0.25251037 0.30125581] | [0.15143743 0.17419272 0.18871523] | [0.59551684 0.61801037 0.63059512] | [0.05607207 0.03963678 0.03171233] | [0.57341416 0.67636814 0.73012258] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 221.6577s, training loss at epoch 16: 287.7811
using time 211.1987s, training loss at epoch 17: 283.6427
using time 217.2126s, training loss at epoch 18: 279.8531
using time 220.9161s, training loss at epoch 19: 276.7240
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 214.27867436408997 | 59.420421838760376 | 273.82330322265625 | [0.18030728 0.25103593 0.29858229] | [0.15056515 0.17295779 0.18719522] | [0.59675277 0.61803797 0.62978829] | [0.05581586 0.03929098 0.0314349 ] | [0.57271083 0.67355483 0.72744323] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 222.0493s, training loss at epoch 21: 271.3614
using time 216.6975s, training loss at epoch 22: 269.0853
using time 215.7193s, training loss at epoch 23: 267.2010
using time 210.4639s, training loss at epoch 24: 265.2338
+-------+--------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |      Loss      |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 215.67850160598755 | 63.31524896621704 | 263.6669921875 | [0.17821263 0.24790507 0.29359443] | [0.14884819 0.17096174 0.18463793] | [0.59809761 0.61833717 0.6293842 ] | [0.05506062 0.03879446 0.03090629] | [0.56795499 0.6691339  0.72191707] |
+-------+--------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 211.4564s, training loss at epoch 26: 262.0901
using time 208.8996s, training loss at epoch 27: 260.7141
using time 213.6041s, training loss at epoch 28: 259.4141
using time 212.8266s, training loss at epoch 29: 258.1681
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 215.47482800483704 | 64.14319705963135 | 257.1995544433594 | [0.17618497 0.24456786 0.28838779] | [0.14713771 0.16880358 0.18193263] | [0.5981364  0.61749807 0.62810646] | [0.05438576 0.03824603 0.03035479] | [0.56463929 0.66447853 0.71595552] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.17618496989192975
early stopping at 30, recall@20:0.1808
