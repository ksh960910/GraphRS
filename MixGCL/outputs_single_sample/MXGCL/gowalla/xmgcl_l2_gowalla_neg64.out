nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 2 --context_hops 3 --pool mean --ns mixgcf --n_negs 64 --K 1 --tau 0.2 --lamb 0.5 --eps 0.1 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
start training ...
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 120.10347700119019 | 74.65641641616821 | 1489.88134765625 | [0.13983026 0.19842455 0.23955235] | [0.11269755 0.13150357 0.143834  ] | [0.64469723 0.66355828 0.67366235] | [0.04243921 0.03043405 0.02472034] | [0.46302498 0.56102217 0.61872865] |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 118.0062s, training loss at epoch 1: 1417.9226
using time 116.7041s, training loss at epoch 2: 1397.3354
using time 117.2021s, training loss at epoch 3: 1383.0093
using time 119.9560s, training loss at epoch 4: 1371.0333
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |  tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 117.90647983551025 | 56.4626100063324 | 1359.828369140625 | [0.12708238 0.1810091  0.2185092 ] | [0.10335567 0.12077399 0.13210455] | [0.65268041 0.66967044 0.67886281] | [0.03896443 0.02806199 0.02281633] | [0.4287963  0.52535334 0.58054793] |
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 117.5426s, training loss at epoch 6: 1348.7415
using time 118.0641s, training loss at epoch 7: 1337.2679
using time 117.3661s, training loss at epoch 8: 1325.0695
using time 127.7043s, training loss at epoch 9: 1310.7784
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 118.81475591659546 | 48.86961054801941 | 1295.22607421875 | [0.15501144 0.21964648 0.26513245] | [0.1261638  0.14693386 0.16052841] | [0.62553506 0.64682807 0.6587038 ] | [0.04693382 0.03368779 0.0273355 ] | [0.50341617 0.60516445 0.6612968 ] |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 119.8526s, training loss at epoch 11: 1279.9248
using time 117.6379s, training loss at epoch 12: 1264.7621
using time 117.7706s, training loss at epoch 13: 1250.6648
using time 116.2091s, training loss at epoch 14: 1238.1753
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 117.50457549095154 | 51.734248876571655 | 1226.5594482421875 | [0.16999451 0.23936113 0.28881539] | [0.14029067 0.16243654 0.17714531] | [0.6092153  0.63221509 0.64521791] | [0.05220376 0.03724714 0.03011477] | [0.54789336 0.65188559 0.70932413] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 119.9435s, training loss at epoch 16: 1216.5089
using time 119.4426s, training loss at epoch 17: 1208.0242
using time 128.5644s, training loss at epoch 18: 1200.2732
using time 114.6505s, training loss at epoch 19: 1193.7910
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 114.88148927688599 | 51.70310425758362 | 1188.110595703125 | [0.17433795 0.24621771 0.29614198] | [0.14491293 0.167796   0.18267024] | [0.60716569 0.62974428 0.64254608] | [0.05392357 0.0384922  0.03106035] | [0.55877822 0.66457901 0.7226204 ] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 119.9587s, training loss at epoch 21: 1183.3586
using time 116.8973s, training loss at epoch 22: 1179.0665
using time 126.7145s, training loss at epoch 23: 1175.4929
using time 117.1884s, training loss at epoch 24: 1172.1560
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 117.45808601379395 | 51.72882866859436 | 1169.35302734375 | [0.17614382 0.24805489 0.29688983] | [0.14616081 0.16900948 0.18362803] | [0.60810958 0.63021457 0.64253799] | [0.05449461 0.03879614 0.03123618] | [0.56269676 0.66772724 0.72406055] |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 119.2819s, training loss at epoch 26: 1166.6499
using time 118.4477s, training loss at epoch 27: 1164.3326
using time 129.1688s, training loss at epoch 28: 1162.1368
using time 117.4279s, training loss at epoch 29: 1160.2814
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 117.28415155410767 | 49.663702964782715 | 1158.6368408203125 | [0.17671034 0.24827313 0.29688529] | [0.14661238 0.16939924 0.18392627] | [0.60900736 0.63046948 0.64239063] | [0.05461518 0.03888656 0.03125963] | [0.56360104 0.66859803 0.72479737] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 120.8485s, training loss at epoch 31: 1157.0327
using time 118.4193s, training loss at epoch 32: 1155.6730
using time 128.6861s, training loss at epoch 33: 1153.9811
using time 117.9770s, training loss at epoch 34: 1152.8176
+-------+--------------------+--------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |      Loss     |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 116.63357162475586 | 52.771960973739624 | 1151.75390625 | [0.17691302 0.24743897 0.29591114] | [0.14678234 0.16919953 0.18367399] | [0.60978382 0.63067177 0.64221229] | [0.05467714 0.03877018 0.03115971] | [0.56480675 0.66745931 0.72322326] |
+-------+--------------------+--------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 122.4364s, training loss at epoch 36: 1150.6912
using time 120.4657s, training loss at epoch 37: 1149.6002
using time 130.8496s, training loss at epoch 38: 1148.5546
using time 118.4182s, training loss at epoch 39: 1147.6951
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   40  | 118.30449891090393 | 53.88510465621948 | 1146.8023681640625 | [0.17642858 0.24588901 0.294162  ] | [0.14639236 0.16844416 0.18286749] | [0.61019248 0.63056903 0.64182311] | [0.05456327 0.0385483  0.03099449] | [0.56406993 0.66508139 0.72067788] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 116.9385s, training loss at epoch 41: 1146.0587
using time 118.2784s, training loss at epoch 42: 1145.3650
using time 130.7201s, training loss at epoch 43: 1144.5609
using time 116.3376s, training loss at epoch 44: 1143.9298
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   45  | 118.35209536552429 | 50.30928659439087 | 1143.197021484375 | [0.17582436 0.24504915 0.29199844] | [0.14581178 0.16776963 0.18178979] | [0.61073081 0.6305895  0.64156312] | [0.05435059 0.03841265 0.03076451] | [0.56222788 0.66390917 0.71796503] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 118.4125s, training loss at epoch 46: 1142.3749
using time 116.8429s, training loss at epoch 47: 1142.1927
using time 129.3283s, training loss at epoch 48: 1141.6588
using time 118.1063s, training loss at epoch 49: 1140.7334
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   50  | 116.72978067398071 | 51.115663290023804 | 1140.2596435546875 | [0.1746548  0.24346621 0.28947651] | [0.14508918 0.16688349 0.18066633] | [0.61095666 0.63043535 0.64111926] | [0.0540207  0.0381196  0.03052225] | [0.55988345 0.66102887 0.71458236] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.1746547970649909
early stopping at 50, recall@20:0.1769
