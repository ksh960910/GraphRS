nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 3 --context_hops 3 --pool mean --ns mixgcf --n_negs 128 --K 1 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
start training ...
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 218.87462258338928 | 56.33906579017639 | 700.2940063476562 | [0.14017368 0.19836847 0.23984776] | [0.11358574 0.13228494 0.14466842] | [0.63527832 0.65615323 0.66782925] | [0.04224496 0.03020045 0.02451883] | [0.46369482 0.56098868 0.61735548] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 213.8694s, training loss at epoch 1: 638.6626
using time 207.2278s, training loss at epoch 2: 612.5591
using time 209.4696s, training loss at epoch 3: 588.7864
using time 212.7049s, training loss at epoch 4: 563.9191
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 206.5141270160675 | 56.29500460624695 | 538.3157348632812 | [0.16460992 0.23069636 0.27857866] | [0.1368098  0.15785745 0.17217046] | [0.59041047 0.61564276 0.63040226] | [0.05056936 0.03587983 0.02911559] | [0.53808025 0.63795298 0.6946547 ] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 212.5114s, training loss at epoch 6: 513.3986
using time 212.2802s, training loss at epoch 7: 490.1483
using time 210.7231s, training loss at epoch 8: 470.5948
using time 209.0700s, training loss at epoch 9: 455.0130
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 212.1363241672516 | 55.865299224853516 | 442.8445739746094 | [0.18068991 0.25341423 0.3046841 ] | [0.15321173 0.17617314 0.19150553] | [0.5752789  0.60079681 0.61561709] | [0.05639192 0.04004873 0.03234309] | [0.57904079 0.68447317 0.73996919] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 206.6861s, training loss at epoch 11: 433.0329
using time 207.6308s, training loss at epoch 12: 425.4248
using time 211.7019s, training loss at epoch 13: 418.8291
using time 207.1474s, training loss at epoch 14: 413.6185
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 210.36160469055176 | 56.11014366149902 | 409.04425048828125 | [0.18436051 0.25751973 0.30871394] | [0.15575438 0.17881288 0.19409962] | [0.5810294  0.60540103 0.61948366] | [0.05745194 0.04060553 0.03270759] | [0.58577266 0.68899457 0.7452609 ] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 212.2526s, training loss at epoch 16: 405.1926
using time 211.1477s, training loss at epoch 17: 401.9522
using time 208.0305s, training loss at epoch 18: 398.9548
using time 208.5367s, training loss at epoch 19: 396.6549
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 211.39799308776855 | 57.502257347106934 | 394.33685302734375 | [0.18535507 0.25785517 0.30912533] | [0.15599432 0.17889386 0.19415093] | [0.58533444 0.60860847 0.62188357] | [0.05766796 0.04068173 0.03268917] | [0.58734677 0.68902807 0.74432313] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 212.9896s, training loss at epoch 21: 392.5113
using time 210.2037s, training loss at epoch 22: 390.7080
using time 208.7096s, training loss at epoch 23: 389.2809
using time 208.3239s, training loss at epoch 24: 387.7249
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 212.3379738330841 | 55.75204873085022 | 386.52410888671875 | [0.1843482  0.25644143 0.30656978] | [0.15493436 0.17770345 0.19266186] | [0.58898238 0.61118011 0.62366225] | [0.05740673 0.0404297  0.03243798] | [0.58523679 0.68611427 0.7399022 ] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 211.0258s, training loss at epoch 26: 385.2940
using time 206.9177s, training loss at epoch 27: 384.1887
using time 211.6749s, training loss at epoch 28: 383.2984
using time 206.9877s, training loss at epoch 29: 382.3466
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 208.84778928756714 | 54.059186697006226 | 381.5437927246094 | [0.18237575 0.25462414 0.30301178] | [0.15326577 0.17610392 0.19056537] | [0.59112457 0.61228869 0.62406608] | [0.0567754  0.04010818 0.03208018] | [0.58101681 0.68310001 0.7358162 ] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 211.3268s, training loss at epoch 31: 380.7448
using time 207.4869s, training loss at epoch 32: 380.0255
using time 208.3723s, training loss at epoch 33: 379.2023
using time 212.2905s, training loss at epoch 34: 378.6473
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 206.71900725364685 | 56.19750237464905 | 378.0127868652344 | [0.18028959 0.25160389 0.29892328] | [0.15140517 0.17393019 0.1881353 ] | [0.59295343 0.61314739 0.62424546] | [0.05614073 0.03960831 0.03169446] | [0.57595954 0.67733941 0.7308594 ] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.18028959474780462
early stopping at 35, recall@20:0.1854
