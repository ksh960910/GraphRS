nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 3 --context_hops 3 --pool mean --ns mixgcf --n_negs 128 --K 1 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
X Mix Simple GCL model setup
start training ...
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 251.53677654266357 | 51.874014377593994 | 700.1619262695312 | [0.14037769 0.19776784 0.23976969] | [0.11359136 0.13211837 0.1446378 ] | [0.63438101 0.65524452 0.66692328] | [0.04223826 0.03018621 0.02453893] | [0.46490053 0.56078773 0.61795834] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 248.6120s, training loss at epoch 1: 638.6625
using time 248.4794s, training loss at epoch 2: 612.5118
using time 243.5435s, training loss at epoch 3: 588.7406
using time 250.0754s, training loss at epoch 4: 563.8157
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 250.36769247055054 | 50.73686480522156 | 538.2394409179688 | [0.16530219 0.2310382  0.27828355] | [0.13716874 0.1580908  0.17223415] | [0.59039101 0.61574563 0.63057949] | [0.05071673 0.03591165 0.02910331] | [0.5395204  0.63919218 0.69338201] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 243.6737s, training loss at epoch 6: 513.2949
using time 243.4910s, training loss at epoch 7: 490.0890
using time 245.5869s, training loss at epoch 8: 470.5626
using time 244.4295s, training loss at epoch 9: 455.0299
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 249.23057866096497 | 50.36734461784363 | 442.8294372558594 | [0.1810403  0.25392083 0.3043142 ] | [0.15318913 0.17619173 0.19126287] | [0.57531777 0.60079711 0.61569552] | [0.05651249 0.04010734 0.03231295] | [0.58138522 0.68591332 0.74013665] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 244.6830s, training loss at epoch 11: 433.0873
using time 243.9640s, training loss at epoch 12: 425.4106
using time 248.9643s, training loss at epoch 13: 418.8406
using time 249.0754s, training loss at epoch 14: 413.6448
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 249.3447289466858 | 51.752382040023804 | 409.1138000488281 | [0.18443276 0.25771683 0.30940463] | [0.15554032 0.17869722 0.19406655] | [0.58111326 0.60546728 0.61952235] | [0.05744189 0.04068508 0.0327489 ] | [0.58677741 0.68979838 0.74562931] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 248.7199s, training loss at epoch 16: 405.2710
using time 250.9013s, training loss at epoch 17: 401.9878
using time 252.3240s, training loss at epoch 18: 399.0352
using time 251.4991s, training loss at epoch 19: 396.7295
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 247.7319483757019 | 51.936251401901245 | 394.3855285644531 | [0.18498064 0.25839015 0.30961604] | [0.15575389 0.17891762 0.19416594] | [0.5853779  0.6085991  0.62187311] | [0.05760098 0.04071103 0.03273271] | [0.58828455 0.68993235 0.74542836] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 244.9178s, training loss at epoch 21: 392.5498
using time 250.3218s, training loss at epoch 22: 390.8038
using time 246.3483s, training loss at epoch 23: 389.3137
using time 250.8958s, training loss at epoch 24: 387.8294
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 250.8213677406311 | 53.06958818435669 | 386.5812683105469 | [0.18389152 0.25725353 0.30715929] | [0.15472488 0.17784187 0.19278483] | [0.58902731 0.61111349 0.6235832 ] | [0.05727443 0.04044477 0.03248878] | [0.58543774 0.68812379 0.74231362] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 250.2080s, training loss at epoch 26: 385.4014
using time 249.4479s, training loss at epoch 27: 384.2645
using time 250.2358s, training loss at epoch 28: 383.4076
using time 251.0983s, training loss at epoch 29: 382.4105
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 244.7025752067566 | 52.23037505149841 | 381.58209228515625 | [0.18198596 0.25433359 0.30368935] | [0.152985   0.17579931 0.19057886] | [0.59108582 0.61217695 0.62397501] | [0.05676703 0.04001859 0.03215051] | [0.58125126 0.68326747 0.73732333] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 244.9563s, training loss at epoch 31: 380.8842
using time 246.3978s, training loss at epoch 32: 380.0740
using time 244.1325s, training loss at epoch 33: 379.3362
using time 245.8717s, training loss at epoch 34: 378.7768
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 246.44797229766846 | 51.25215744972229 | 378.07464599609375 | [0.18022989 0.25113316 0.2997778 ] | [0.15126599 0.17367813 0.18823825] | [0.59295328 0.61314394 0.62429295] | [0.05616585 0.03957147 0.03175977] | [0.57713176 0.67646862 0.73196463] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.1802298949661709
early stopping at 35, recall@20:0.1850
