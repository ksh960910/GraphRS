nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 3 --context_hops 3 --pool mean --ns mixgcf --n_negs 64 --K 1 --alpha 0.5 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
X Mix Simple GCL model setup
start training ...
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 136.07763361930847 | 56.59690546989441 | 494.78082275390625 | [0.13014333 0.18443639 0.22328745] | [0.10478362 0.12231493 0.13392011] | [0.6363489  0.65746839 0.66948908] | [0.03839842 0.02752947 0.02241387] | [0.4287963  0.52331034 0.57897381] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 138.2965s, training loss at epoch 1: 431.3001
using time 141.3682s, training loss at epoch 2: 403.4495
using time 121.8852s, training loss at epoch 3: 377.5331
using time 137.6493s, training loss at epoch 4: 351.0324
+-------+--------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |      Loss      |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 141.03911972045898 | 57.09918141365051 | 324.9541015625 | [0.16114635 0.22551392 0.27184456] | [0.13438209 0.1548294  0.16864268] | [0.58913212 0.6152907  0.63061748] | [0.04916773 0.03477711 0.02815828] | [0.52816666 0.62572845 0.68172684] |
+-------+--------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 134.9076s, training loss at epoch 6: 300.2672
using time 132.1936s, training loss at epoch 7: 277.7594
using time 139.8479s, training loss at epoch 8: 259.3958
using time 140.3444s, training loss at epoch 9: 244.9417
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 140.40732216835022 | 56.69397497177124 | 233.70156860351562 | [0.18179028 0.25451895 0.30537034] | [0.1538478  0.17676607 0.19198034] | [0.57186041 0.59760941 0.61277989] | [0.05674191 0.040212   0.03241956] | [0.58426552 0.68758792 0.74077299] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 145.1636s, training loss at epoch 11: 224.7930
using time 121.9572s, training loss at epoch 12: 217.6212
using time 135.6200s, training loss at epoch 13: 211.7252
using time 137.0302s, training loss at epoch 14: 206.8305
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 136.83825182914734 | 57.59547829627991 | 202.7042999267578 | [0.18494896 0.25802331 0.3097471 ] | [0.15610738 0.17916875 0.19460458] | [0.57756519 0.60215927 0.61636944] | [0.05767131 0.04073113 0.03282649] | [0.58962422 0.69020028 0.74603121] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 128.0722s, training loss at epoch 16: 199.1613
using time 141.2258s, training loss at epoch 17: 196.1357
using time 122.7470s, training loss at epoch 18: 193.4227
using time 133.2704s, training loss at epoch 19: 191.0891
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 119.90959978103638 | 62.30811953544617 | 189.0376434326172 | [0.1850062  0.25822542 0.30915874] | [0.15573923 0.17886138 0.19410403] | [0.58134858 0.60480284 0.61812132] | [0.05757251 0.04067335 0.03274555] | [0.58999263 0.69016679 0.74512693] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 142.0498s, training loss at epoch 21: 187.2079
using time 140.5145s, training loss at epoch 22: 185.6466
using time 132.1352s, training loss at epoch 23: 184.1557
using time 134.2616s, training loss at epoch 24: 182.8234
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 122.17560148239136 | 60.43029522895813 | 181.7252197265625 | [0.18439324 0.25625617 0.30518268] | [0.15475701 0.17746776 0.19209179] | [0.58432989 0.60655546 0.61891858] | [0.0572895  0.04036774 0.03231295] | [0.58748074 0.68711903 0.74000268] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 139.5772s, training loss at epoch 26: 180.5744
using time 139.7337s, training loss at epoch 27: 179.6169
using time 139.8024s, training loss at epoch 28: 178.6834
using time 138.4593s, training loss at epoch 29: 177.7620
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 123.60368633270264 | 57.216262102127075 | 177.0365447998047 | [0.18222348 0.25323809 0.30012152] | [0.15279432 0.17525361 0.18930852] | [0.58610724 0.60708711 0.61869638] | [0.05658115 0.03986871 0.03181727] | [0.58198808 0.68256414 0.73481144] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 129.6986s, training loss at epoch 31: 176.2630
using time 115.9789s, training loss at epoch 32: 175.5696
using time 116.8185s, training loss at epoch 33: 174.9049
using time 117.2554s, training loss at epoch 34: 174.3803
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 116.65900111198425 | 57.71531558036804 | 173.77281188964844 | [0.17957657 0.2487055  0.29452632] | [0.15038138 0.17228844 0.18604213] | [0.58760731 0.60739474 0.61837253] | [0.05578907 0.03924911 0.03129647] | [0.57659589 0.67620068 0.72764418] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.17957656508855044
early stopping at 35, recall@20:0.1850
