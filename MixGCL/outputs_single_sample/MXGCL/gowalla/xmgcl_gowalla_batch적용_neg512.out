nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 2 --context_hops 3 --pool mean --ns mixgcf --n_negs 512 --K 1 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
X Mix Simple GCL model setup
start training ...
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 923.1227281093597 | 49.069663286209106 | 701.0829467773438 | [0.14061639 0.19845235 0.23963329] | [0.1142753  0.13291847 0.14525962] | [0.63557182 0.65636014 0.66803917] | [0.04205741 0.0299995  0.024367  ] | [0.46483355 0.56075424 0.61742247] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 918.6012s, training loss at epoch 1: 640.2925
using time 922.2189s, training loss at epoch 2: 615.0309
using time 914.7798s, training loss at epoch 3: 592.4930
using time 917.6332s, training loss at epoch 4: 568.6297
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 916.3157880306244 | 50.528050899505615 | 543.5385131835938 | [0.16537736 0.23242193 0.27912181] | [0.13751214 0.1588497  0.17283088] | [0.59108448 0.61640808 0.63119732] | [0.05070668 0.0360071  0.02909885] | [0.53875008 0.63932614 0.69324804] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 917.6917s, training loss at epoch 6: 518.5535
using time 909.9520s, training loss at epoch 7: 495.0561
using time 916.5331s, training loss at epoch 8: 474.9590
using time 919.0311s, training loss at epoch 9: 458.8143
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 906.8502180576324 | 51.889084339141846 | 445.9181213378906 | [0.1817238  0.25471707 0.30573769] | [0.15392515 0.17694411 0.19219413] | [0.57443609 0.59982472 0.61469907] | [0.05667158 0.04016763 0.03240561] | [0.58178713 0.68758792 0.74174426] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 889.0765s, training loss at epoch 11: 435.7236
using time 921.7596s, training loss at epoch 12: 427.5829
using time 923.6672s, training loss at epoch 13: 420.8249
using time 925.5916s, training loss at epoch 14: 415.3792
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 926.506420135498 | 62.700865507125854 | 410.6344909667969 | [0.1843661  0.25815232 0.30941493] | [0.15595414 0.17918045 0.19446355] | [0.5804793  0.60459674 0.61858023] | [0.05751055 0.04065745 0.03270257] | [0.58624154 0.68953044 0.74643312] |
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 922.2483s, training loss at epoch 16: 406.7379
using time 926.3631s, training loss at epoch 17: 403.2076
using time 923.8675s, training loss at epoch 18: 400.2815
using time 925.7371s, training loss at epoch 19: 397.7669
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 926.2603344917297 | 61.64335584640503 | 395.50799560546875 | [0.18493192 0.25786187 0.30866526] | [0.15591358 0.1789026  0.19408081] | [0.58443534 0.60734379 0.62044187] | [0.05753065 0.04056116 0.03261884] | [0.58567218 0.68926251 0.74492598] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 925.3933s, training loss at epoch 21: 393.5435
using time 924.8698s, training loss at epoch 22: 391.5896
using time 922.6085s, training loss at epoch 23: 390.1429
using time 898.8562s, training loss at epoch 24: 388.5576
+-------+-------------------+-----------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |  tesing time(s) |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-----------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 897.1961529254913 | 62.545166015625 | 387.1956787109375 | [0.18405246 0.25570056 0.30615287] | [0.15477813 0.17740797 0.19247893] | [0.58745972 0.60927279 0.62145396] | [0.05718735 0.04023461 0.03236207] | [0.58399759 0.68551142 0.74130886] |
+-------+-------------------+-----------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 894.1781s, training loss at epoch 26: 386.0829
using time 889.6723s, training loss at epoch 27: 384.9171
using time 892.9337s, training loss at epoch 28: 383.9433
using time 878.9602s, training loss at epoch 29: 382.9960
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 868.5204892158508 | 60.02836513519287 | 382.08087158203125 | [0.18195389 0.25313233 0.30142975] | [0.15297177 0.17545318 0.18992102] | [0.58963291 0.61028975 0.6217116 ] | [0.05659455 0.03981764 0.03190211] | [0.58027999 0.68048764 0.73524684] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 853.1487s, training loss at epoch 31: 381.2260
using time 855.3173s, training loss at epoch 32: 380.5616
using time 854.4050s, training loss at epoch 33: 379.8863
using time 853.9372s, training loss at epoch 34: 379.1863
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 854.2394177913666 | 62.45805549621582 | 378.61346435546875 | [0.18057332 0.24919039 0.29664612] | [0.15138292 0.17304402 0.1872641 ] | [0.59092302 0.61055858 0.6213167 ] | [0.05613069 0.03924241 0.03143267] | [0.57770112 0.67479403 0.72871592] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.180573315323028
early stopping at 35, recall@20:0.1849
