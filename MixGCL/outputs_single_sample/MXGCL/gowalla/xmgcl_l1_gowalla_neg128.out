nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 3 --context_hops 3 --pool mean --ns mixgcf --n_negs 128 --K 1 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
start training ...
+-------+-------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |  tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 216.0896441936493 | 50.4437038898468 | 581.5921630859375 | [0.14203292 0.20212202 0.24504245] | [0.11513411 0.13433781 0.14716501] | [0.63549653 0.65559808 0.66688541] | [0.0436198  0.03130568 0.02548005] | [0.47431174 0.57338067 0.63189095] |
+-------+-------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 217.0709s, training loss at epoch 1: 520.5225
using time 218.7422s, training loss at epoch 2: 496.2175
using time 215.5871s, training loss at epoch 3: 476.1069
using time 218.4897s, training loss at epoch 4: 456.4671
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 231.76748371124268 | 66.16285562515259 | 435.48162841796875 | [0.15952443 0.22490588 0.27187504] | [0.13105202 0.15199695 0.16600213] | [0.60432999 0.62758914 0.64105582] | [0.0488663  0.03494792 0.02833802] | [0.52354478 0.62576194 0.68152589] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 216.2621s, training loss at epoch 6: 413.9634
using time 212.9912s, training loss at epoch 7: 391.8607
using time 211.4965s, training loss at epoch 8: 370.9990
using time 215.4507s, training loss at epoch 9: 352.6405
+-------+-------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |  tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 215.5634469985962 | 53.8238422870636 | 337.6200256347656 | [0.17830808 0.24965587 0.30083299] | [0.15046831 0.17292533 0.18821909] | [0.57895517 0.60410119 0.61877227] | [0.05573046 0.03940736 0.03189374] | [0.57435193 0.67780829 0.73554826] |
+-------+-------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 229.2691s, training loss at epoch 11: 325.3108
using time 210.4342s, training loss at epoch 12: 315.5188
using time 219.5025s, training loss at epoch 13: 307.0832
using time 218.9301s, training loss at epoch 14: 300.5184
+-------+-------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |      Loss      |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 220.7955720424652 | 63.64362812042236 | 294.7587890625 | [0.18173772 0.25428282 0.30641661] | [0.15363907 0.17652178 0.19206286] | [0.58398301 0.60826534 0.62232587] | [0.05679215 0.04017433 0.03247427] | [0.5794427  0.68373635 0.74207917] |
+-------+-------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 219.0472s, training loss at epoch 16: 289.8337
using time 211.8878s, training loss at epoch 17: 285.7871
using time 206.2739s, training loss at epoch 18: 282.0650
using time 215.3086s, training loss at epoch 19: 279.2401
+-------+-------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |      Loss      |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 211.8220841884613 | 61.95909380912781 | 276.3447265625 | [0.18427314 0.25603024 0.3075781 ] | [0.15489494 0.17749587 0.19285128] | [0.58845607 0.61177538 0.62517984] | [0.05735984 0.04036774 0.03254572] | [0.58309331 0.68608078 0.7423806 ] |
+-------+-------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 223.1398s, training loss at epoch 21: 274.1220
using time 215.4388s, training loss at epoch 22: 271.8814
using time 214.6680s, training loss at epoch 23: 270.1906
using time 217.2928s, training loss at epoch 24: 268.2928
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 220.60973238945007 | 73.13619422912598 | 266.9319152832031 | [0.18340141 0.25586576 0.30711327] | [0.15433211 0.17722495 0.19247391] | [0.5925417  0.61493797 0.62774763] | [0.05709693 0.04034262 0.03246701] | [0.58048094 0.68467412 0.74130886] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 208.3305s, training loss at epoch 26: 265.4215
using time 219.9322s, training loss at epoch 27: 264.1606
using time 213.6070s, training loss at epoch 28: 263.0462
using time 213.2520s, training loss at epoch 29: 261.9415
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 215.43889617919922 | 77.56040811538696 | 260.9845886230469 | [0.18274786 0.25428711 0.30584988] | [0.15353477 0.17612805 0.19146276] | [0.59516874 0.61673903 0.62896074] | [0.05691272 0.04009227 0.0323029 ] | [0.57863889 0.68132494 0.73966776] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 215.5263s, training loss at epoch 31: 260.0687
using time 208.0467s, training loss at epoch 32: 259.1317
using time 208.2487s, training loss at epoch 33: 258.2721
using time 220.0929s, training loss at epoch 34: 257.6410
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 212.92070412635803 | 78.78935599327087 | 256.85736083984375 | [0.18173448 0.2528132  0.30317771] | [0.15235241 0.17480561 0.18983265] | [0.59776082 0.6184279  0.63013005] | [0.05654264 0.03981512 0.03204445] | [0.5765289  0.67831067 0.73544779] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.1817344760075975
early stopping at 35, recall@20:0.1843
