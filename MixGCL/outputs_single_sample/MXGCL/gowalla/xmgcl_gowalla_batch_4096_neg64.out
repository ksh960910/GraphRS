nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 4096 --gpu_id 3 --context_hops 3 --pool mean --ns mixgcf --n_negs 64 --K 1 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
X Mix Simple GCL model setup
start training ...
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 73.30148911476135 | 55.99556303024292 | 409.7562561035156 | [0.14469237 0.20572853 0.2479242 ] | [0.11718082 0.13674257 0.14939381] | [0.62669611 0.64830194 0.66070745] | [0.04419419 0.03172014 0.02571449] | [0.48258423 0.58309331 0.63872329] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 71.6152s, training loss at epoch 1: 375.8832
using time 70.5573s, training loss at epoch 2: 363.9565
using time 71.5131s, training loss at epoch 3: 355.4258
using time 72.9242s, training loss at epoch 4: 347.9299
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 74.26837038993835 | 106.16869258880615 | 340.5570068359375 | [0.14351664 0.20227276 0.24369134] | [0.11688897 0.13576241 0.14815221] | [0.62303116 0.64497328 0.65741864] | [0.0431057  0.03083428 0.02500447] | [0.46905352 0.56450533 0.61836024] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 70.7358s, training loss at epoch 6: 333.0435
using time 71.4155s, training loss at epoch 7: 325.3859
using time 70.4122s, training loss at epoch 8: 317.6882
using time 70.7484s, training loss at epoch 9: 310.1481
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 70.52799272537231 | 56.56431579589844 | 302.6238098144531 | [0.17112254 0.24023145 0.28854654] | [0.14311023 0.16498926 0.17948353] | [0.58033253 0.60605176 0.62117883] | [0.05296236 0.03759713 0.03040614] | [0.55640029 0.65881841 0.71461585] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 70.6689s, training loss at epoch 11: 295.6129
using time 70.3343s, training loss at epoch 12: 289.0298
using time 70.5743s, training loss at epoch 13: 283.1620
using time 70.1696s, training loss at epoch 14: 278.0527
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 70.40674448013306 | 63.85509991645813 | 273.6664123535156 | [0.17987168 0.25178915 0.30275017] | [0.15191859 0.17460682 0.18985665] | [0.57314336 0.59886677 0.613944  ] | [0.05612901 0.03978163 0.03215609] | [0.57910778 0.68125795 0.73819412] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 77.2564s, training loss at epoch 16: 269.8225
using time 74.7345s, training loss at epoch 17: 266.4087
using time 70.6443s, training loss at epoch 18: 263.4118
using time 70.6564s, training loss at epoch 19: 260.8899
+-------+------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 70.5435254573822 | 66.06025004386902 | 258.56622314453125 | [0.18293407 0.25654979 0.30738425] | [0.15464888 0.17790266 0.1930728 ] | [0.57715178 0.60210664 0.61666581] | [0.05705506 0.04054022 0.03261996] | [0.58332775 0.68742046 0.74341885] |
+-------+------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 71.3254s, training loss at epoch 21: 256.6053
using time 71.2520s, training loss at epoch 22: 254.7171
using time 70.6293s, training loss at epoch 23: 253.0931
using time 71.4082s, training loss at epoch 24: 251.5662
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 70.71751642227173 | 65.74483847618103 | 250.23960876464844 | [0.18450311 0.25773874 0.30950656] | [0.15576034 0.1788691  0.19430102] | [0.58137376 0.60553322 0.6195107 ] | [0.05752562 0.04070517 0.03280025] | [0.58567218 0.68802331 0.74492598] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 70.1988s, training loss at epoch 26: 249.0159
using time 72.0948s, training loss at epoch 27: 247.9695
using time 81.0088s, training loss at epoch 28: 246.9105
using time 85.0085s, training loss at epoch 29: 245.9826
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 71.15642976760864 | 64.71877264976501 | 245.1182403564453 | [0.18480119 0.25817555 0.30969026] | [0.15558226 0.17870971 0.19406252] | [0.58471943 0.60810685 0.62151874] | [0.05768303 0.04074285 0.03281309] | [0.58597361 0.68815728 0.74505995] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 71.2493s, training loss at epoch 31: 244.3558
using time 70.1868s, training loss at epoch 32: 243.6476
using time 70.7922s, training loss at epoch 33: 242.8832
using time 71.3006s, training loss at epoch 34: 242.3170
+-------+------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 70.8443124294281 | 67.01982569694519 | 241.77828979492188 | [0.1848733  0.25743212 0.3086647 ] | [0.15536611 0.17819489 0.19347169] | [0.58775164 0.61029964 0.62314984] | [0.05769141 0.04059967 0.03267466] | [0.58630853 0.68715252 0.74351932] |
+-------+------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 71.0333s, training loss at epoch 36: 241.1767
using time 70.5064s, training loss at epoch 37: 240.6631
using time 70.6250s, training loss at epoch 38: 240.1889
using time 70.7021s, training loss at epoch 39: 239.6686
+-------+------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   40  | 70.7121217250824 | 66.91528654098511 | 239.31626892089844 | [0.18419613 0.25627734 0.30689877] | [0.15446548 0.17716343 0.19227507] | [0.5902092  0.61193968 0.62425754] | [0.05744189 0.04042803 0.03251111] | [0.58473441 0.68490857 0.74117489] |
+-------+------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 86.9519s, training loss at epoch 41: 238.8819
using time 72.5009s, training loss at epoch 42: 238.5028
using time 71.5972s, training loss at epoch 43: 238.1573
using time 70.3570s, training loss at epoch 44: 237.8352
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   45  | 70.70146083831787 | 67.22377467155457 | 237.54273986816406 | [0.18317427 0.25466019 0.30476565] | [0.15337375 0.1758714  0.19084002] | [0.59246208 0.6133964  0.62513044] | [0.05715386 0.04018437 0.03229788] | [0.5827249  0.68135843 0.73725635] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 71.9503s, training loss at epoch 46: 237.2306
using time 70.5785s, training loss at epoch 47: 236.9720
using time 70.6306s, training loss at epoch 48: 236.7286
using time 70.7451s, training loss at epoch 49: 236.3901
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   50  | 82.64711880683899 | 68.22999954223633 | 236.1531219482422 | [0.18176831 0.25258429 0.30179943] | [0.15208305 0.17435522 0.18909483] | [0.59423438 0.61437988 0.62563179] | [0.05675698 0.03985113 0.03201878] | [0.57863889 0.67797575 0.73363923] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.18176830844932085
early stopping at 50, recall@20:0.1849
