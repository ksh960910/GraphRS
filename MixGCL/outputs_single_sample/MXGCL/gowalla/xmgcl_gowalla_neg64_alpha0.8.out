nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 3 --context_hops 3 --pool mean --ns mixgcf --n_negs 64 --K 1 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
X Mix Simple GCL model setup
start training ...
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 120.74104523658752 | 56.44551134109497 | 359.0133972167969 | [0.13086848 0.18554543 0.22420352] | [0.1055784  0.12322847 0.13480131] | [0.63345849 0.65497139 0.66724966] | [0.03866468 0.027712   0.02255509] | [0.43301628 0.52655905 0.58195459] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 119.2320s, training loss at epoch 1: 294.8016
using time 118.6981s, training loss at epoch 2: 265.9910
using time 118.0377s, training loss at epoch 3: 239.1200
using time 135.2384s, training loss at epoch 4: 212.0233
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 136.88055109977722 | 52.194005489349365 | 185.66983032226562 | [0.16286654 0.22806147 0.27488563] | [0.13606697 0.15675747 0.17074292] | [0.58446908 0.61085764 0.62638839] | [0.04992632 0.03533726 0.02861824] | [0.53600375 0.63410141 0.68976489] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 141.0982s, training loss at epoch 6: 160.8731
using time 121.9133s, training loss at epoch 7: 138.6771
using time 137.9563s, training loss at epoch 8: 120.9276
using time 141.0498s, training loss at epoch 9: 107.0979
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 136.64540672302246 | 53.55762600898743 | 96.34221649169922 | [0.18148906 0.25393172 0.30462977] | [0.15366587 0.17648878 0.1916969 ] | [0.5712088  0.59710371 0.61229233] | [0.05664813 0.04011069 0.03238328] | [0.58369616 0.68695157 0.74144283] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 131.9711s, training loss at epoch 11: 87.8033
using time 140.0305s, training loss at epoch 12: 80.9189
using time 140.6978s, training loss at epoch 13: 75.2607
using time 140.4337s, training loss at epoch 14: 70.5469
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 145.21978878974915 | 55.54359292984009 | 66.56275177001953 | [0.18439917 0.25766531 0.30956208] | [0.15597676 0.17911519 0.19458126] | [0.57728146 0.60200039 0.61632876] | [0.05749883 0.04067084 0.03278016] | [0.58841851 0.69006631 0.74663407] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 121.9289s, training loss at epoch 16: 63.1351
using time 135.2607s, training loss at epoch 17: 60.2152
using time 137.4102s, training loss at epoch 18: 57.5644
using time 137.0081s, training loss at epoch 19: 55.2975
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 130.40790939331055 | 53.54452204704285 | 53.31081771850586 | [0.18516932 0.25769853 0.3090994 ] | [0.15606527 0.17897157 0.19431133] | [0.58131144 0.60485847 0.61826181] | [0.05763614 0.04062814 0.03272825] | [0.58992565 0.68963092 0.74439011] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 141.1131s, training loss at epoch 21: 51.5279
using time 122.8810s, training loss at epoch 22: 50.0030
using time 133.3132s, training loss at epoch 23: 48.5549
using time 119.9433s, training loss at epoch 24: 47.2395
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 145.0284779071808 | 52.15901827812195 | 46.167572021484375 | [0.18398444 0.2559521  0.30543206] | [0.15457956 0.17730063 0.19215012] | [0.58446896 0.60679572 0.61932433] | [0.05719573 0.04028401 0.03237044] | [0.58594012 0.68678411 0.73963427] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 140.2351s, training loss at epoch 26: 45.0419
using time 133.5395s, training loss at epoch 27: 44.1117
using time 133.0721s, training loss at epoch 28: 43.1916
using time 121.9840s, training loss at epoch 29: 42.2827
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 141.3232901096344 | 52.94818830490112 | 41.570980072021484 | [0.1822891  0.25313753 0.30103721] | [0.15279944 0.17515752 0.18955329] | [0.58652025 0.60761438 0.61932757] | [0.05665316 0.03983438 0.03192668] | [0.582323   0.68145891 0.7353808 ] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 139.7467s, training loss at epoch 31: 40.8119
using time 138.7715s, training loss at epoch 32: 40.1095
using time 140.8047s, training loss at epoch 33: 39.4613
using time 121.1623s, training loss at epoch 34: 38.9551
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 130.2764275074005 | 55.32116889953613 | 38.34818649291992 | [0.1799982  0.24894926 0.29582122] | [0.15066836 0.17244434 0.1865479 ] | [0.58798472 0.60802342 0.61905208] | [0.0559515  0.03922818 0.03143044] | [0.57649541 0.67492799 0.72811307] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.17999819566728437
early stopping at 35, recall@20:0.1852
