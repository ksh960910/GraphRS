cll 1ë¡œ
nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 3 --context_hops 3 --pool mean --ns mixgcf --n_negs 64 --K 1 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
start training ...
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 115.85759568214417 | 48.803855895996094 | 581.4578857421875 | [0.14061315 0.20146332 0.24361699] | [0.11401808 0.13343233 0.14602301] | [0.63276904 0.65323904 0.66488929] | [0.04357626 0.03147649 0.0255381 ] | [0.47230223 0.57395003 0.63061826] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 112.0384s, training loss at epoch 1: 520.0295
using time 109.7973s, training loss at epoch 2: 495.2590
using time 110.9236s, training loss at epoch 3: 474.6321
using time 114.7818s, training loss at epoch 4: 454.1576
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 108.68794298171997 | 48.61218619346619 | 432.52960205078125 | [0.15773938 0.22242531 0.26905247] | [0.12958028 0.15026747 0.16420538] | [0.60489948 0.62810795 0.64152966] | [0.04847947 0.03462975 0.02811586] | [0.52026258 0.621408   0.67841115] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 107.4874s, training loss at epoch 6: 410.0066
using time 109.6769s, training loss at epoch 7: 388.1483
using time 111.5614s, training loss at epoch 8: 367.8992
using time 109.3593s, training loss at epoch 9: 349.9770
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 109.63350915908813 | 48.28848838806152 | 335.2537536621094 | [0.17653408 0.24681347 0.2970437 ] | [0.14862327 0.17080995 0.18582301] | [0.58050082 0.60541743 0.62006795] | [0.05521301 0.0390917  0.03158617] | [0.57250988 0.67392324 0.73039052] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 111.7909s, training loss at epoch 11: 323.5995
using time 112.3151s, training loss at epoch 12: 313.8214
using time 112.1889s, training loss at epoch 13: 305.9999
using time 108.6819s, training loss at epoch 14: 299.4539
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 112.58243322372437 | 55.33430051803589 | 293.80230712890625 | [0.18049287 0.25238217 0.30400741] | [0.15213926 0.17485768 0.19019276] | [0.58555637 0.60968151 0.62384227] | [0.05639862 0.03998593 0.03225155] | [0.57800255 0.68045415 0.73876348] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 109.5047s, training loss at epoch 16: 289.0748
using time 108.9580s, training loss at epoch 17: 285.1360
using time 109.4482s, training loss at epoch 18: 281.5951
using time 111.8375s, training loss at epoch 19: 278.6443
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |  tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 108.74734807014465 | 55.2347047328949 | 275.8291931152344 | [0.18221892 0.25495768 0.30610247] | [0.15334139 0.17630397 0.19153974] | [0.59001728 0.61337399 0.62690176] | [0.05688425 0.04030159 0.03246031] | [0.58088285 0.68457365 0.74050506] |
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 114.7351s, training loss at epoch 21: 273.4986
using time 109.7340s, training loss at epoch 22: 271.4630
using time 108.8773s, training loss at epoch 23: 269.6352
using time 109.4606s, training loss at epoch 24: 267.9306
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 114.48440384864807 | 50.28686594963074 | 266.5460510253906 | [0.18288959 0.25484828 0.30618415] | [0.15343479 0.17612608 0.19144681] | [0.593987   0.61648092 0.62947129] | [0.05705339 0.04025219 0.03245361] | [0.58145221 0.68340143 0.73899792] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 118.6297s, training loss at epoch 26: 265.0778
using time 116.9369s, training loss at epoch 27: 263.8474
using time 118.0435s, training loss at epoch 28: 262.6451
using time 116.3346s, training loss at epoch 29: 261.5370
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 125.64894580841064 | 58.99416518211365 | 260.6457214355469 | [0.18255466 0.25430217 0.30498776] | [0.15294088 0.17556678 0.19068861] | [0.59677711 0.61848614 0.63099461] | [0.05694286 0.04014837 0.03232076] | [0.58172014 0.68172684 0.73749079] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 119.2329s, training loss at epoch 31: 259.6481
using time 115.8962s, training loss at epoch 32: 258.9032
using time 117.3857s, training loss at epoch 33: 257.9918
using time 117.1683s, training loss at epoch 34: 257.2846
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 116.75362968444824 | 60.33424401283264 | 256.5857238769531 | [0.18168127 0.25275561 0.30286097] | [0.15200277 0.17441524 0.18941095] | [0.59957928 0.62060444 0.63264398] | [0.05668498 0.0399156  0.0321494 ] | [0.57997857 0.6798513  0.73477795] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 119.0851s, training loss at epoch 36: 256.0548
using time 116.7972s, training loss at epoch 37: 255.3075
using time 117.0750s, training loss at epoch 38: 254.6298
using time 124.9009s, training loss at epoch 39: 254.0590
+-------+--------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |       Loss      |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   40  | 119.84534454345703 | 58.887635231018066 | 253.52587890625 | [0.18004248 0.25129799 0.30038781] | [0.15067505 0.17316779 0.18784674] | [0.60167133 0.62202843 0.63357437] | [0.05625628 0.03970963 0.03190993] | [0.57622748 0.67680354 0.73183067] |
+-------+--------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.1800424773687979
early stopping at 40, recall@20:0.1829
