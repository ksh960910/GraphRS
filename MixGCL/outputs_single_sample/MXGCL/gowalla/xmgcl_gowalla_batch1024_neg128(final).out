nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 1024 --gpu_id 1 --context_hops 3 --pool mean --ns mixgcf --n_negs 128 --K 1 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
start training ...
+-------+--------------------+-----------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |  tesing time(s) |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-----------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 418.21360063552856 | 59.762531042099 | 1177.9915771484375 | [0.12729165 0.18123858 0.2190095 ] | [0.10300848 0.12045117 0.13176761] | [0.64073301 0.66110508 0.67247247] | [0.03810537 0.027429   0.02228102] | [0.42688727 0.52046353 0.57508875] |
+-------+--------------------+-----------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 405.4085s, training loss at epoch 1: 1056.5077
using time 403.3201s, training loss at epoch 2: 978.6764
using time 389.5958s, training loss at epoch 3: 894.0747
using time 397.0642s, training loss at epoch 4: 813.5449
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 395.9211699962616 | 56.82444429397583 | 751.4090576171875 | [0.17746792 0.24828855 0.29943644] | [0.15009643 0.1724448  0.187724  ] | [0.57265134 0.59863145 0.61375757] | [0.0554575  0.03928344 0.03178657] | [0.57595954 0.67958336 0.73477795] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 393.2366s, training loss at epoch 6: 709.5482
using time 408.7082s, training loss at epoch 7: 680.7391
using time 396.4995s, training loss at epoch 8: 660.4351
using time 400.6125s, training loss at epoch 9: 645.2698
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 399.20612835884094 | 58.98764371871948 | 633.6868896484375 | [0.1827493  0.25542552 0.30781316] | [0.15427741 0.17722706 0.19287873] | [0.58165388 0.60603673 0.62010143] | [0.05701152 0.04032922 0.03264228] | [0.58433251 0.6884922  0.74449059] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 392.7191s, training loss at epoch 11: 624.6088
using time 390.5019s, training loss at epoch 12: 617.3721
using time 395.4677s, training loss at epoch 13: 611.3591
using time 388.1025s, training loss at epoch 14: 606.2064
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 396.3329212665558 | 57.295668840408325 | 602.0645751953125 | [0.18283612 0.25574901 0.30650872] | [0.1540636  0.17716056 0.19229958] | [0.58666631 0.6097558  0.62279612] | [0.05691774 0.04031248 0.03243017] | [0.58443298 0.68675062 0.74261504] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 392.0766s, training loss at epoch 16: 598.2646
using time 386.6037s, training loss at epoch 17: 595.2348
using time 389.9357s, training loss at epoch 18: 591.8752
using time 391.8177s, training loss at epoch 19: 589.4436
+-------+--------------------+-------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |      Loss     |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 389.93441915512085 | 59.76414203643799 | 587.095703125 | [0.1814374  0.25388221 0.30352623] | [0.1527691  0.17570171 0.19053803] | [0.58964987 0.61148504 0.6235661 ] | [0.0564656  0.03996919 0.03209079] | [0.58205506 0.68306651 0.73899792] |
+-------+--------------------+-------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 386.6091s, training loss at epoch 21: 584.9089
using time 389.1588s, training loss at epoch 22: 583.3110
using time 386.8779s, training loss at epoch 23: 581.5625
using time 389.1525s, training loss at epoch 24: 579.6776
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 395.24989914894104 | 57.50669717788696 | 578.1790161132812 | [0.17884178 0.24996028 0.29772716] | [0.15050101 0.17299869 0.18729469] | [0.59215909 0.61266296 0.62401961] | [0.05573883 0.03937471 0.03152756] | [0.57575859 0.67532989 0.73082591] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 387.0130s, training loss at epoch 26: 576.9836
using time 396.2862s, training loss at epoch 27: 575.5038
using time 389.9065s, training loss at epoch 28: 574.2805
using time 388.3880s, training loss at epoch 29: 573.2377
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 390.0071144104004 | 58.94914412498474 | 572.3143310546875 | [0.17628006 0.2451777  0.29122331] | [0.14813307 0.16995076 0.18374221] | [0.59317164 0.61260172 0.62323859] | [0.05494507 0.03870738 0.03091969] | [0.57006497 0.66849756 0.72195057] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.1762800640985306
early stopping at 30, recall@20:0.1828
