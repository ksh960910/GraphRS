nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 3 --context_hops 3 --pool mean --ns mixgcf --n_negs 128 --K 1 --tau 0.2 --lamb 0.5 --eps 0.1 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
start training ...
+-------+-------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |       Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 220.2762327194214 | 52.129626989364624 | 1573.12451171875 | [0.13052492 0.18821932 0.23132283] | [0.10416938 0.1227409  0.13561562] | [0.64163465 0.66160698 0.67283707] | [0.04002612 0.02911615 0.02398352] | [0.44313082 0.54387434 0.60432715] |
+-------+-------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 216.4981s, training loss at epoch 1: 1439.1340
using time 209.6126s, training loss at epoch 2: 1409.0275
using time 210.5480s, training loss at epoch 3: 1389.5149
using time 210.0611s, training loss at epoch 4: 1375.7577
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 209.33363127708435 | 51.78924322128296 | 1364.468505859375 | [0.1153199  0.16691205 0.20360695] | [0.09108683 0.10779904 0.11881265] | [0.65949282 0.67559379 0.68433705] | [0.03522004 0.02578036 0.02114564] | [0.39316096 0.4905218  0.54742448] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 210.0198s, training loss at epoch 6: 1355.3949
using time 215.0072s, training loss at epoch 7: 1345.8918
using time 208.6067s, training loss at epoch 8: 1336.9209
using time 209.7895s, training loss at epoch 9: 1326.5961
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 210.98688983917236 | 51.96843147277832 | 1315.2955322265625 | [0.13610229 0.194969   0.23783196] | [0.10803549 0.1270388  0.13984781] | [0.64414187 0.66285146 0.67321071] | [0.0410426  0.02970644 0.02435528] | [0.45046554 0.55097461 0.61045616] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 207.3526s, training loss at epoch 11: 1303.3048
using time 208.6193s, training loss at epoch 12: 1290.2070
using time 208.7671s, training loss at epoch 13: 1276.8971
using time 212.3944s, training loss at epoch 14: 1264.4930
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 208.24431896209717 | 52.53280687332153 | 1252.6153564453125 | [0.15867499 0.22469052 0.27170895] | [0.12954903 0.15060558 0.16468082] | [0.62004775 0.6418018  0.65429621] | [0.04861511 0.03469338 0.0282275 ] | [0.51667895 0.62006832 0.67764083] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 207.7088s, training loss at epoch 16: 1241.8879
using time 211.6564s, training loss at epoch 17: 1232.6714
using time 208.7250s, training loss at epoch 18: 1224.1899
using time 208.0890s, training loss at epoch 19: 1217.3573
+-------+-------------------+--------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |      Loss     |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 207.8751814365387 | 51.371724367141724 | 1210.98828125 | [0.16608958 0.23474328 0.2825281 ] | [0.13692447 0.15878554 0.17310074] | [0.6135914  0.63545652 0.64805461] | [0.05128274 0.03663675 0.02965146] | [0.53808025 0.6428093  0.69964499] |
+-------+-------------------+--------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 208.4908s, training loss at epoch 21: 1205.7306
using time 209.0284s, training loss at epoch 22: 1200.7675
using time 207.6818s, training loss at epoch 23: 1196.7566
using time 213.1297s, training loss at epoch 24: 1192.9287
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 209.86039900779724 | 52.71129322052002 | 1189.7332763671875 | [0.1681884  0.2373073  0.28570297] | [0.13908937 0.16112794 0.17556515] | [0.61360354 0.63491251 0.6471575 ] | [0.05204133 0.0371835  0.03003718] | [0.54250117 0.64769911 0.70574051] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 211.8813s, training loss at epoch 26: 1186.5376
using time 206.9222s, training loss at epoch 27: 1183.9413
using time 213.0878s, training loss at epoch 28: 1181.5283
using time 207.0515s, training loss at epoch 29: 1179.2225
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 208.59345722198486 | 53.62906217575073 | 1177.114501953125 | [0.16923926 0.23797473 0.28647069] | [0.14008482 0.16196157 0.17639364] | [0.61398812 0.63479942 0.64657082] | [0.05246835 0.03737189 0.03014714] | [0.54581687 0.64870386 0.70644383] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 207.5475s, training loss at epoch 31: 1175.2614
using time 206.9926s, training loss at epoch 32: 1173.3995
using time 208.0813s, training loss at epoch 33: 1171.8774
using time 215.1431s, training loss at epoch 34: 1170.2585
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 207.77723622322083 | 53.583776235580444 | 1168.7525634765625 | [0.16954243 0.23814642 0.28578642] | [0.14020719 0.16204194 0.17622423] | [0.61482216 0.63505684 0.64640111] | [0.05252026 0.03741711 0.03009634] | [0.54628575 0.64910577 0.70553955] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 213.4013s, training loss at epoch 36: 1167.4302
using time 208.6686s, training loss at epoch 37: 1165.8179
using time 207.7747s, training loss at epoch 38: 1164.8934
using time 212.5386s, training loss at epoch 39: 1163.6035
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   40  | 208.8897361755371 | 52.14480996131897 | 1162.8006591796875 | [0.16936419 0.23713174 0.28418979] | [0.14004438 0.16156458 0.17560068] | [0.61554232 0.63527502 0.64624362] | [0.05254538 0.03730575 0.0299914 ] | [0.54574988 0.6469288  0.70275973] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 206.6326s, training loss at epoch 41: 1161.4083
using time 214.0479s, training loss at epoch 42: 1160.4761
using time 209.0751s, training loss at epoch 43: 1159.5582
using time 207.8697s, training loss at epoch 44: 1158.7000
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   45  | 214.40918135643005 | 54.24702334403992 | 1157.88818359375 | [0.16830351 0.23593689 0.28236747] | [0.13943774 0.16088369 0.17476679] | [0.61599224 0.63521586 0.64578303] | [0.05229252 0.03709056 0.02982841] | [0.54219975 0.64468484 0.70058276] |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 207.9980s, training loss at epoch 46: 1157.0779
using time 208.1319s, training loss at epoch 47: 1156.2777
using time 209.3669s, training loss at epoch 48: 1155.7240
using time 209.3854s, training loss at epoch 49: 1154.8573
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   50  | 207.51461720466614 | 53.05082035064697 | 1154.21826171875 | [0.16730523 0.23431536 0.27978538] | [0.13865395 0.15988324 0.1735068 ] | [0.6160975  0.63491269 0.64514882] | [0.05203965 0.03685779 0.02960011] | [0.54102753 0.64167057 0.6966977 ] |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.1673052330901362
early stopping at 50, recall@20:0.1695
