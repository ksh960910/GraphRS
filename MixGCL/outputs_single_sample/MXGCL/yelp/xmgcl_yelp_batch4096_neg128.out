nohup python main.py --dataset yelp2018 --gnn xmgcl --dim 64 --lr 0.001 --batch_size 4096 --gpu_id 1 --context_hops 3 --pool mean --ns mixgcf --n_negs 128 --K 1 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
X Mix Simple GCL model setup
start training ...
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 216.38860845565796 | 70.41234254837036 | 632.2687377929688 | [0.06302744 0.10316072 0.1351525 ] | [0.05189741 0.06699851 0.0781727 ] | [0.56385253 0.57936639 0.58935065] | [0.02825723 0.02331139 0.0204823 ] | [0.3799419  0.51979917 0.60347985] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 235.3181s, training loss at epoch 1: 577.6561
using time 195.3779s, training loss at epoch 2: 561.5469
using time 202.6239s, training loss at epoch 3: 551.6581
using time 187.1073s, training loss at epoch 4: 543.7637
+-------+--------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |       Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 208.23037600517273 | 54.292664527893066 | 536.589111328125 | [0.06254786 0.10003938 0.12990913] | [0.05209574 0.06617808 0.07665578] | [0.57287518 0.58851495 0.59848109] | [0.02813882 0.02274062 0.0198639 ] | [0.37444739 0.50464191 0.58162814] |
+-------+--------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 192.6022s, training loss at epoch 6: 529.2451
using time 201.0457s, training loss at epoch 7: 521.3196
using time 185.1414s, training loss at epoch 8: 512.0211
using time 206.8658s, training loss at epoch 9: 501.2419
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 208.79625725746155 | 69.10527086257935 | 489.3981628417969 | [0.06953326 0.11366401 0.1494557 ] | [0.05745832 0.07404698 0.08655116] | [0.52983854 0.54639936 0.55722235] | [0.03128079 0.02576891 0.02271904] | [0.41227738 0.5596817  0.64525704] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 207.1426s, training loss at epoch 11: 476.4291
using time 191.9350s, training loss at epoch 12: 463.1370
using time 211.5536s, training loss at epoch 13: 450.7848
using time 191.2996s, training loss at epoch 14: 440.2742
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 210.98112273216248 | 65.78985714912415 | 431.6884460449219 | [0.07172724 0.11729017 0.15453889] | [0.05921102 0.0763714  0.08935175] | [0.51759246 0.53382402 0.54438253] | [0.03224864 0.02661677 0.02347954] | [0.42506631 0.57297587 0.66120374] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 196.4091s, training loss at epoch 16: 424.3881
using time 200.5242s, training loss at epoch 17: 418.3755
using time 195.5758s, training loss at epoch 18: 413.2699
using time 222.9792s, training loss at epoch 19: 408.9510
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 189.25103664398193 | 54.25367999076843 | 405.19500732421875 | [0.07241245 0.11834005 0.15541711] | [0.05960054 0.07689699 0.08979215] | [0.52171517 0.53754511 0.547752  ] | [0.032536   0.02687176 0.02359532] | [0.42655046 0.57777567 0.66211949] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 197.4523s, training loss at epoch 21: 402.0304
using time 190.5005s, training loss at epoch 22: 399.1870
using time 188.6676s, training loss at epoch 23: 396.7469
using time 190.7768s, training loss at epoch 24: 394.4893
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 190.58323550224304 | 58.87598514556885 | 392.4508056640625 | [0.07259635 0.11841691 0.15536108] | [0.05969136 0.07693973 0.08978923] | [0.52450082 0.53991881 0.54988664] | [0.03260547 0.02689545 0.02360637] | [0.42718201 0.57805987 0.66158267] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 188.9501s, training loss at epoch 26: 390.6788
using time 191.3578s, training loss at epoch 27: 389.1223
using time 198.6779s, training loss at epoch 28: 387.5741
using time 191.5679s, training loss at epoch 29: 386.2488
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 189.506587266922 | 63.11604881286621 | 384.9273376464844 | [0.07208953 0.11818469 0.1547916 ] | [0.0595645  0.07689154 0.08966395] | [0.52640819 0.54149907 0.55127563] | [0.03240969 0.02678492 0.02354217] | [0.42569787 0.5768915  0.66003537] |
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 191.7136s, training loss at epoch 31: 383.9407
using time 183.2994s, training loss at epoch 32: 382.7965
using time 192.4003s, training loss at epoch 33: 381.7765
using time 191.6800s, training loss at epoch 34: 380.8483
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 190.76837348937988 | 71.05880165100098 | 380.0153503417969 | [0.07190425 0.11770099 0.15377204] | [0.05940867 0.07660148 0.08920521] | [0.52794651 0.54272797 0.55232914] | [0.03235443 0.02667993 0.02341112] | [0.42497158 0.5747758  0.65880384] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 197.1431s, training loss at epoch 36: 379.2218
using time 192.7685s, training loss at epoch 37: 378.4045
using time 187.0396s, training loss at epoch 38: 377.7616
using time 189.3346s, training loss at epoch 39: 377.0540
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   40  | 189.49589610099792 | 58.059664487838745 | 376.4794006347656 | [0.07161204 0.11724879 0.15282671] | [0.0591144  0.07626709 0.08869706] | [0.52892861 0.54342447 0.55282085] | [0.03215549 0.02658441 0.02327534] | [0.42260326 0.5720917  0.65776178] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.07161204073567645
early stopping at 40, recall@20:0.0726
