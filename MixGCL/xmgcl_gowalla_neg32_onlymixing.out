nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 2 --context_hops 3 --pool mean --ns mixgcf --n_negs 32 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
X Mix Simple GCL model setup
start training ...
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 83.67208623886108 | 65.85574507713318 | 590.3424682617188 | [0.14928417 0.21209966 0.25689847] | [0.12210083 0.14213824 0.15557774] | [0.61125907 0.63356902 0.64675166] | [0.04666756 0.03351363 0.02727521] | [0.50090428 0.60292049 0.65875142] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 82.0071s, training loss at epoch 1: 523.9599
using time 92.0926s, training loss at epoch 2: 496.6289
using time 80.9438s, training loss at epoch 3: 474.6096
using time 80.2443s, training loss at epoch 4: 452.3955
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 82.39441800117493 | 55.842753887176514 | 428.8479309082031 | [0.16511529 0.2324203  0.28008545] | [0.13701588 0.15840015 0.17270951] | [0.58901192 0.61309254 0.627399  ] | [0.05114542 0.03640147 0.02951191] | [0.54049166 0.64301025 0.69810436] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 81.5908s, training loss at epoch 6: 405.4039
using time 81.4448s, training loss at epoch 7: 382.2046
using time 106.5128s, training loss at epoch 8: 361.6575
using time 81.1896s, training loss at epoch 9: 344.3434
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 81.03956770896912 | 57.72096061706543 | 329.7555847167969 | [0.17973732 0.25172272 0.30278881] | [0.15147331 0.17424961 0.18948974] | [0.57428913 0.59929941 0.61412341] | [0.05594481 0.03973558 0.03209302] | [0.57672985 0.68011923 0.73695492] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 80.5520s, training loss at epoch 11: 317.9478
using time 82.4407s, training loss at epoch 12: 308.0100
using time 82.2252s, training loss at epoch 13: 300.1051
using time 81.2515s, training loss at epoch 14: 293.5795
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 83.12910223007202 | 62.90621566772461 | 287.9866638183594 | [0.18413192 0.25677393 0.3085202 ] | [0.15505511 0.1780836  0.19349514] | [0.58006108 0.6041185  0.61823486] | [0.05723759 0.04059465 0.03270424] | [0.5839641  0.68661665 0.74479202] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 80.8143s, training loss at epoch 16: 282.9737
using time 85.7915s, training loss at epoch 17: 278.9521
using time 80.7722s, training loss at epoch 18: 275.1407
using time 80.4434s, training loss at epoch 19: 272.0362
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 78.52249312400818 | 54.88164234161377 | 269.31292724609375 | [0.18474924 0.25870784 0.30991659] | [0.15573221 0.17910859 0.19440329] | [0.58477516 0.6078125  0.62124494] | [0.05756916 0.0408023  0.03284547] | [0.58533726 0.68986536 0.74586376] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 82.6943s, training loss at epoch 21: 266.7690
using time 92.6816s, training loss at epoch 22: 264.5875
using time 81.4121s, training loss at epoch 23: 262.6159
using time 80.7461s, training loss at epoch 24: 261.0423
+-------+------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |  tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 80.6468985080719 | 55.4900541305542 | 259.2535705566406 | [0.18447692 0.25753226 0.30825442] | [0.15526055 0.17831818 0.19347018] | [0.58873349 0.61086587 0.6236105 ] | [0.0574938  0.04062144 0.03267913] | [0.58460044 0.68735347 0.74348583] |
+-------+------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 80.6442s, training loss at epoch 26: 257.7635
using time 83.5522s, training loss at epoch 27: 256.4576
using time 80.2754s, training loss at epoch 28: 255.2659
using time 79.7818s, training loss at epoch 29: 254.3277
+-------+------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 80.1284646987915 | 51.44348454475403 | 253.20787048339844 | [0.18313003 0.25564823 0.30526939] | [0.15409488 0.1770144  0.19181215] | [0.59179977 0.61301121 0.6251363 ] | [0.057112   0.04036774 0.03238607] | [0.58269141 0.68306651 0.73862951] |
+-------+------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 82.0215s, training loss at epoch 31: 252.0668
using time 80.8251s, training loss at epoch 32: 251.2253
using time 81.2752s, training loss at epoch 33: 250.5892
using time 81.1800s, training loss at epoch 34: 249.5604
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 80.28600430488586 | 51.984358072280884 | 248.89395141601562 | [0.18208207 0.25283345 0.30130163] | [0.15279759 0.17516798 0.18967329] | [0.59430146 0.61465367 0.62620967] | [0.05675028 0.03997756 0.0320478 ] | [0.58031348 0.67824369 0.73343827] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.18208206609541708
early stopping at 35, recall@20:0.1847
