nohup python main.py --dataset yelp2018 --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 0 --context_hops 3 --pool mean --ns mixgcf --n_negs 32 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
X Mix Simple GCL model setup
start training ...
+-------+--------------------+-------------------+--------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |     Loss     |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 175.49063348770142 | 59.78105020523071 | 902.05859375 | [0.06282289 0.10298799 0.13580039] | [0.05191854 0.06704761 0.0785269 ] | [0.5535854  0.56874155 0.57886491] | [0.0283646  0.02343296 0.02071281] | [0.38158393 0.52131489 0.60569029] |
+-------+--------------------+-------------------+--------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 177.9266s, training loss at epoch 1: 800.9552
using time 169.9595s, training loss at epoch 2: 767.4925
using time 169.9016s, training loss at epoch 3: 742.5577
using time 168.1138s, training loss at epoch 4: 717.2436
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 179.06488680839539 | 56.67956829071045 | 686.3184814453125 | [0.06872909 0.11217422 0.14660638] | [0.05679145 0.07310875 0.0851552 ] | [0.5358071  0.55172774 0.56212101] | [0.03100606 0.02546024 0.02234222] | [0.40905646 0.55494505 0.63682582] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 169.0836s, training loss at epoch 6: 650.3466
using time 171.8356s, training loss at epoch 7: 609.4515
using time 171.7921s, training loss at epoch 8: 570.4510
using time 174.5195s, training loss at epoch 9: 538.5536
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 169.49326968193054 | 56.867589473724365 | 513.9059448242188 | [0.07156755 0.11732886 0.15384254] | [0.05886174 0.07608068 0.08879718] | [0.51750865 0.53356525 0.54393084] | [0.03220601 0.02662467 0.02338533] | [0.42434003 0.57234432 0.65728811] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 166.9523s, training loss at epoch 11: 495.4909
using time 172.8363s, training loss at epoch 12: 481.2895
using time 174.4578s, training loss at epoch 13: 469.7921
using time 165.2994s, training loss at epoch 14: 460.9337
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 165.46550154685974 | 56.653664350509644 | 453.2481384277344 | [0.07219925 0.11855878 0.15487674] | [0.05957619 0.07701051 0.08965891] | [0.52268909 0.53820399 0.54826626] | [0.03247442 0.02689545 0.02354375] | [0.42585575 0.57679677 0.66047745] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 169.2440s, training loss at epoch 16: 446.5734
using time 173.4757s, training loss at epoch 17: 441.3527
using time 168.9240s, training loss at epoch 18: 436.5727
using time 167.2748s, training loss at epoch 19: 432.3345
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 165.29740715026855 | 74.32116198539734 | 428.5799560546875 | [0.07204239 0.11856411 0.15424195] | [0.05959848 0.07705618 0.08950765] | [0.52546329 0.5406128  0.55036847] | [0.0324539  0.02687966 0.0234648 ] | [0.4246558  0.57651257 0.6571618 ] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 165.7634s, training loss at epoch 21: 425.4463
using time 166.7101s, training loss at epoch 22: 422.3965
using time 165.8374s, training loss at epoch 23: 419.8340
using time 172.4493s, training loss at epoch 24: 416.9825
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 166.34801769256592 | 57.16848707199097 | 414.8144226074219 | [0.07163617 0.11776436 0.15308821] | [0.05929025 0.07661318 0.08897141] | [0.52749292 0.54222932 0.55178823] | [0.03223285 0.02669098 0.02331481] | [0.42342428 0.57458633 0.65564608] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 166.6768s, training loss at epoch 26: 412.8724
using time 168.3216s, training loss at epoch 27: 410.7847
using time 166.1652s, training loss at epoch 28: 408.8499
using time 166.2894s, training loss at epoch 29: 407.1490
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 164.37841296195984 | 55.38416528701782 | 405.5396728515625 | [0.07124189 0.11681114 0.15209778] | [0.05897967 0.07609815 0.08842318] | [0.52873034 0.54316382 0.55251224] | [0.03207497 0.02651809 0.02317218] | [0.42178224 0.5708286  0.65359353] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.07124189389748246
early stopping at 30, recall@20:0.0722
