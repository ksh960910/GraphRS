nohup python main.py --dataset yelp2018 --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 2 --context_hops 3 --pool mean --ns mixgcf --n_negs 64 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
X Mix Simple GCL model setup
start training ...
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 256.1590201854706 | 78.50326299667358 | 899.9249267578125 | [0.06318465 0.10351492 0.13549977] | [0.05220871 0.06735424 0.07856598] | [0.55736682 0.57264205 0.58269273] | [0.02850354 0.02345664 0.0206365 ] | [0.38316281 0.52276746 0.60578502] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 256.4537s, training loss at epoch 1: 800.8528
using time 244.6395s, training loss at epoch 2: 768.2780
using time 258.4656s, training loss at epoch 3: 744.4867
using time 243.3666s, training loss at epoch 4: 721.2005
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+---------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |            hit_ratio            |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+---------------------------------+
|   5   | 252.86180329322815 | 57.18142223358154 | 693.0333251953125 | [0.06894715 0.11184833 0.14677495] | [0.05701337 0.07317896 0.0853337 ] | [0.5397092  0.55572201 0.56610859] | [0.03099975 0.02541525 0.02229696] | [0.4101301 0.5519136 0.6357206] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+---------------------------------+
using time 248.5904s, training loss at epoch 6: 658.1235
using time 248.6944s, training loss at epoch 7: 618.4068
using time 244.8098s, training loss at epoch 8: 578.6967
using time 254.9989s, training loss at epoch 9: 545.5794
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 254.21772575378418 | 53.31829643249512 | 519.3057861328125 | [0.07177939 0.11809818 0.15438751] | [0.05919063 0.07665922 0.0893047 ] | [0.51760523 0.53377238 0.54424956] | [0.03225654 0.02677229 0.02345217] | [0.4257926  0.57487053 0.65965644] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 241.3403s, training loss at epoch 11: 500.5078
using time 252.0891s, training loss at epoch 12: 485.5284
using time 244.1164s, training loss at epoch 13: 473.6551
using time 248.2318s, training loss at epoch 14: 463.8047
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 244.5650987625122 | 54.90783619880676 | 455.97845458984375 | [0.07213329 0.11868269 0.15526868] | [0.05943762 0.0769772  0.08972245] | [0.52239998 0.53806866 0.5481984 ] | [0.03239548 0.02688992 0.02356901] | [0.42535051 0.57654415 0.66095112] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 244.5526s, training loss at epoch 16: 449.2806
using time 249.5803s, training loss at epoch 17: 443.5349
using time 246.5277s, training loss at epoch 18: 438.7491
using time 247.0640s, training loss at epoch 19: 434.3407
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 241.68840432167053 | 53.48481798171997 | 430.60638427734375 | [0.07217082 0.11825252 0.15458741] | [0.059413   0.07674022 0.08942432] | [0.5250079  0.54026555 0.5501287 ] | [0.03238127 0.02675177 0.02348217] | [0.4246558  0.57610206 0.65937224] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 232.5585s, training loss at epoch 21: 427.3086
using time 206.8767s, training loss at epoch 22: 424.0471
using time 206.6750s, training loss at epoch 23: 421.1772
using time 208.2217s, training loss at epoch 24: 418.6461
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 208.0496506690979 | 52.791064977645874 | 416.1758728027344 | [0.07217371 0.11746197 0.1532116 ] | [0.05917208 0.07618659 0.08870463] | [0.52651206 0.5413851  0.55098158] | [0.03233706 0.02656704 0.02331428] | [0.42424529 0.57351269 0.65668814] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 210.2277s, training loss at epoch 26: 414.5121
using time 207.8296s, training loss at epoch 27: 412.6184
using time 207.4757s, training loss at epoch 28: 410.3301
using time 206.0542s, training loss at epoch 29: 408.8853
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 207.0059278011322 | 52.659098863601685 | 406.9000244140625 | [0.07141534 0.11639569 0.15152581] | [0.05874279 0.07562581 0.08794012] | [0.52735083 0.54194374 0.55124808] | [0.0320797  0.02636415 0.02309482] | [0.42143489 0.57057598 0.65390931] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 208.5894s, training loss at epoch 31: 405.4604
using time 205.6828s, training loss at epoch 32: 403.8511
using time 207.7989s, training loss at epoch 33: 402.8209
using time 212.0965s, training loss at epoch 34: 401.4440
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 206.1496741771698 | 52.60581159591675 | 400.4407043457031 | [0.07091485 0.1153084  0.14982461] | [0.05837031 0.07502279 0.08712692] | [0.52808973 0.54231719 0.55136944] | [0.03188234 0.02613995 0.0228643 ] | [0.41991916 0.56703928 0.6505305 ] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 207.5812s, training loss at epoch 36: 399.3500
using time 208.5345s, training loss at epoch 37: 398.0790
using time 206.0501s, training loss at epoch 38: 396.8963
using time 207.8433s, training loss at epoch 39: 396.1539
+-------+------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |  tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   40  | 208.246253490448 | 52.6580171585083 | 394.9971008300781 | [0.0704667  0.11391387 0.14777041] | [0.05790053 0.07420939 0.086085  ] | [0.52876222 0.54258363 0.55144458] | [0.03168972 0.02589523 0.02261221] | [0.41827713 0.56296577 0.64598333] |
+-------+------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.07046669753300669
early stopping at 40, recall@20:0.0722
