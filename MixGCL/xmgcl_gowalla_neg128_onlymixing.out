nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 0 --context_hops 3 --pool mean --ns mixgcf --n_negs 128 --K 1 &
기존의 final*(l*) 없애고 그냥 mixing된거의 matmul만 사용한 실험결과
reading train and test user-item set ...
building the adj mat ...
loading over ...
X Mix Simple GCL model setup
start training ...
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 252.54280424118042 | 68.13963532447815 | 586.4215087890625 | [0.15012838 0.21115403 0.25431051] | [0.12299502 0.14245761 0.15538259] | [0.6204927  0.64197854 0.65430031] | [0.04627905 0.03295683 0.02668911] | [0.49624891 0.59675799 0.65272289] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 237.1573s, training loss at epoch 1: 522.9498
using time 232.7569s, training loss at epoch 2: 498.0258
using time 240.1967s, training loss at epoch 3: 477.8745
using time 236.4339s, training loss at epoch 4: 458.0782
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 236.79736304283142 | 72.80749750137329 | 436.5660400390625 | [0.16750785 0.2347971  0.28119425] | [0.13881479 0.1602191  0.17416585] | [0.59452468 0.61839285 0.63243705] | [0.05135475 0.03642994 0.02940809] | [0.54163038 0.64378056 0.697535  ] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 245.9845s, training loss at epoch 6: 413.8414
using time 235.3140s, training loss at epoch 7: 390.8163
using time 238.5149s, training loss at epoch 8: 369.1805
using time 230.5214s, training loss at epoch 9: 350.3476
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 234.4709620475769 | 60.71477198600769 | 334.9948425292969 | [0.18313667 0.255036   0.30639268] | [0.15450062 0.1771479  0.19250622] | [0.5738774  0.59927015 0.61417893] | [0.05693114 0.04012409 0.03241007] | [0.58238998 0.68527698 0.74211267] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 243.9268s, training loss at epoch 11: 322.3626
using time 235.4325s, training loss at epoch 12: 312.2313
using time 231.3928s, training loss at epoch 13: 303.5767
using time 230.6231s, training loss at epoch 14: 296.7896
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 225.8573293685913 | 58.40919613838196 | 290.8482360839844 | [0.18590831 0.2591423  0.31064385] | [0.15687324 0.17997948 0.19534041] | [0.57930015 0.60359765 0.61772966] | [0.05776844 0.04074452 0.03280919] | [0.58751423 0.69060218 0.74670105] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 233.4052s, training loss at epoch 16: 285.6224
using time 231.4108s, training loss at epoch 17: 281.4236
using time 232.5341s, training loss at epoch 18: 277.6043
using time 229.1328s, training loss at epoch 19: 274.4779
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 226.7904555797577 | 58.53682780265808 | 271.51080322265625 | [0.18604586 0.25885146 0.31044047] | [0.15679837 0.17980603 0.19519682] | [0.58331014 0.60652458 0.61980502] | [0.0578036  0.04070098 0.03279467] | [0.58738027 0.68963092 0.74626566] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 220.6744s, training loss at epoch 21: 269.1240
using time 219.5926s, training loss at epoch 22: 266.8689
using time 227.8354s, training loss at epoch 23: 264.9626
using time 222.3435s, training loss at epoch 24: 263.0031
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 219.7335114479065 | 59.40862274169922 | 261.5036926269531 | [0.18476261 0.25727231 0.30731101] | [0.15567775 0.17863601 0.19354692] | [0.58690121 0.60890519 0.62139398] | [0.05737658 0.04046319 0.03245361] | [0.58446647 0.68661665 0.74251457] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 228.7782s, training loss at epoch 26: 259.9562
using time 223.7550s, training loss at epoch 27: 258.6533
using time 219.3167s, training loss at epoch 28: 257.4002
using time 216.8143s, training loss at epoch 29: 256.2331
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 217.83799815177917 | 57.02335977554321 | 255.11520385742188 | [0.18290434 0.25436575 0.30241243] | [0.15387776 0.17645965 0.19089723] | [0.58884824 0.6098502  0.62162479] | [0.05680722 0.03998426 0.03203217] | [0.58061491 0.6827316  0.73658651] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 218.5086s, training loss at epoch 31: 254.2766
using time 216.6998s, training loss at epoch 32: 253.2868
using time 221.3858s, training loss at epoch 33: 252.4201
using time 218.5741s, training loss at epoch 34: 251.6475
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 219.83008694648743 | 58.65230345726013 | 250.84628295898438 | [0.18059797 0.25071313 0.29737235] | [0.15188949 0.17406808 0.18811174] | [0.59054091 0.61052562 0.62171525] | [0.05608882 0.0394442  0.03155324] | [0.57579208 0.67683703 0.7304575 ] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.180597974748562
early stopping at 35, recall@20:0.1860
