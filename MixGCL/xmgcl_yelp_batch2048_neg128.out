nohup python main.py --dataset yelp2018 --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 2 --context_hops 3 --pool mean --ns mixgcf --n_negs 128 --K 1 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
X Mix Simple GCL model setup
start training ...
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 382.6591737270355 | 107.9947612285614 | 1076.5750732421875 | [0.06179636 0.10065721 0.13147457] | [0.05101568 0.06563216 0.07645772] | [0.57098846 0.5865215  0.59656873] | [0.02763515 0.02269957 0.019966  ] | [0.37220538 0.50678919 0.58778578] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 358.0548s, training loss at epoch 1: 982.9507
using time 372.1589s, training loss at epoch 2: 952.4569
using time 378.7035s, training loss at epoch 3: 927.1780
using time 378.4692s, training loss at epoch 4: 899.2421
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 376.82016706466675 | 67.14217495918274 | 864.0046997070312 | [0.06927505 0.11281914 0.14764206] | [0.05706349 0.07345633 0.08561341] | [0.53681529 0.55335301 0.56401701] | [0.03108343 0.02557155 0.02243274] | [0.41123532 0.55636605 0.63935203] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 390.9626s, training loss at epoch 6: 821.7001
using time 384.8421s, training loss at epoch 7: 776.8276
using time 381.7132s, training loss at epoch 8: 739.1432
using time 376.9888s, training loss at epoch 9: 711.8807
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 375.1314413547516 | 72.33341956138611 | 691.9305419921875 | [0.07241542 0.11857681 0.15481334] | [0.05958015 0.07693683 0.08956436] | [0.51962648 0.53570903 0.54608256] | [0.03249495 0.02684808 0.02349585] | [0.42724517 0.57736516 0.66044588] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 371.2708s, training loss at epoch 11: 677.1178
using time 347.5021s, training loss at epoch 12: 665.6387
using time 348.5443s, training loss at epoch 13: 656.2598
using time 370.3931s, training loss at epoch 14: 648.9105
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 361.9611551761627 | 63.95801901817322 | 642.8552856445312 | [0.07274098 0.11867254 0.15526237] | [0.05992388 0.07715117 0.0899304 ] | [0.52412533 0.53983724 0.54995358] | [0.03267652 0.02685834 0.02359111] | [0.42822407 0.57736516 0.66148794] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 362.3675s, training loss at epoch 16: 637.3580
using time 374.7190s, training loss at epoch 17: 632.8093
using time 353.4466s, training loss at epoch 18: 628.8032
using time 366.6855s, training loss at epoch 19: 625.2999
+-------+-------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |       Loss      |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 378.7295024394989 | 55.62431502342224 | 622.12158203125 | [0.07250429 0.11819185 0.15419961] | [0.05975188 0.07691715 0.08950039] | [0.52626703 0.54161863 0.55150335] | [0.03249811 0.02676519 0.02344743] | [0.42601364 0.57597575 0.66019326] |
+-------+-------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 352.1543s, training loss at epoch 21: 619.3019
using time 374.4908s, training loss at epoch 22: 616.7812
using time 359.0895s, training loss at epoch 23: 614.5840
using time 362.4954s, training loss at epoch 24: 612.3660
+-------+-------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |  tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 351.1551465988159 | 58.2200129032135 | 610.2429809570312 | [0.07210564 0.11765398 0.15298333] | [0.05944033 0.07653994 0.08890554] | [0.52745325 0.54248028 0.55211878] | [0.03237653 0.02664914 0.02330007] | [0.42386636 0.57483895 0.65706707] |
+-------+-------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 359.9613s, training loss at epoch 26: 608.5652
using time 365.6253s, training loss at epoch 27: 606.8979
using time 360.0369s, training loss at epoch 28: 605.2631
using time 356.3058s, training loss at epoch 29: 603.7919
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 359.03349447250366 | 61.60332441329956 | 602.2182006835938 | [0.07157722 0.1166363  0.1513049 ] | [0.05905308 0.07597454 0.08812428] | [0.52820803 0.54292551 0.55235007] | [0.03212865 0.02643047 0.02307482] | [0.42143489 0.57123911 0.65413035] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.07157721880774422
early stopping at 30, recall@20:0.0727
