nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 4096 --gpu_id 3 --context_hops 3 --pool mean --ns mixgcf --n_negs 128 --K 1 --eps 0.1 --lamb 0.1 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
X Mix Simple GCL model setup
start training ...
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 104.5292227268219 | 48.078014612197876 | 267.6973876953125 | [0.14356552 0.20376889 0.24584939] | [0.11594461 0.13533949 0.14792587] | [0.63958568 0.65946723 0.6705018 ] | [0.04329493 0.03107626 0.0251976 ] | [0.47277112 0.56906022 0.62606337] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 103.2459s, training loss at epoch 1: 252.3333
using time 106.9035s, training loss at epoch 2: 247.7623
using time 103.6079s, training loss at epoch 3: 243.8782
using time 103.5490s, training loss at epoch 4: 239.8479
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 104.59480357170105 | 58.730698347091675 | 235.08880615234375 | [0.12562439 0.17846788 0.21510016] | [0.10173797 0.11876625 0.12969796] | [0.63453406 0.65499727 0.66653568] | [0.0374439  0.02692829 0.02183055] | [0.41221783 0.50077031 0.55351999] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 102.5361s, training loss at epoch 6: 228.8230
using time 102.3948s, training loss at epoch 7: 220.9734
using time 101.3944s, training loss at epoch 8: 211.7355
using time 99.6573s, training loss at epoch 9: 201.4886
+-------+--------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |       Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 103.51456594467163 | 50.834537982940674 | 190.734130859375 | [0.16685228 0.23530299 0.28265482] | [0.14051881 0.16208952 0.17623088] | [0.54841026 0.57616701 0.59270922] | [0.05187387 0.03693734 0.02985353] | [0.55700315 0.66223458 0.7189363 ] |
+-------+--------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 102.8037s, training loss at epoch 11: 180.8577
using time 102.8147s, training loss at epoch 12: 172.8148
using time 104.1816s, training loss at epoch 13: 166.6907
using time 103.5862s, training loss at epoch 14: 161.7905
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 103.97108817100525 | 53.24897599220276 | 157.8494110107422 | [0.17607795 0.24620939 0.29632799] | [0.14947227 0.17148031 0.18642458] | [0.552223   0.57962759 0.59588024] | [0.05499196 0.03885642 0.03141537] | [0.5765289  0.67995177 0.73625159] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 103.1307s, training loss at epoch 16: 154.5191
using time 105.3738s, training loss at epoch 17: 151.7495
using time 103.5919s, training loss at epoch 18: 149.2885
using time 103.5591s, training loss at epoch 19: 147.1640
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 103.06596612930298 | 50.30633330345154 | 145.36766052246094 | [0.18013868 0.25194829 0.30382038] | [0.153264   0.17585457 0.1913194 ] | [0.56088081 0.58740936 0.60312606] | [0.05628977 0.03983271 0.03225155] | [0.58299283 0.68762141 0.74315091] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 99.8575s, training loss at epoch 21: 143.7189
using time 107.0661s, training loss at epoch 22: 142.1577
using time 103.0420s, training loss at epoch 23: 140.8492
using time 103.5764s, training loss at epoch 24: 139.6610
+-------+--------------------+------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |  tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 103.84177541732788 | 51.1066620349884 | 138.65121459960938 | [0.18296162 0.25570448 0.30767512] | [0.1551844  0.17810058 0.19360092] | [0.56709769 0.59276745 0.60796331] | [0.0570919  0.04041882 0.03265177] | [0.58694487 0.69150646 0.74623217] |
+-------+--------------------+------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 99.0938s, training loss at epoch 26: 137.7143
using time 103.6701s, training loss at epoch 27: 136.8020
using time 100.3868s, training loss at epoch 28: 136.0528
using time 98.7919s, training loss at epoch 29: 135.2675
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 102.32147216796875 | 52.468382596969604 | 134.63497924804688 | [0.18420194 0.257778   0.30949053] | [0.15602764 0.17920971 0.19465313] | [0.57173879 0.59670826 0.61143908] | [0.05747371 0.04071941 0.03284379] | [0.58871994 0.69298011 0.74824168] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 103.3796s, training loss at epoch 31: 133.9961
using time 106.3147s, training loss at epoch 32: 133.3660
using time 104.9301s, training loss at epoch 33: 132.8650
using time 103.8120s, training loss at epoch 34: 132.2870
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 103.00159311294556 | 49.12515687942505 | 131.8557586669922 | [0.18484111 0.25908593 0.31084844] | [0.15629602 0.17970112 0.19515912] | [0.57524745 0.59962973 0.6139042 ] | [0.05762777 0.04088017 0.03295041] | [0.58915534 0.69284614 0.74988278] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 103.3916s, training loss at epoch 36: 131.4657
using time 108.2090s, training loss at epoch 37: 131.0621
using time 103.1219s, training loss at epoch 38: 130.6899
using time 99.5981s, training loss at epoch 39: 130.3257
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   40  | 99.65081882476807 | 51.586007595062256 | 130.0291748046875 | [0.18547476 0.25921012 0.31116595] | [0.15625301 0.1794828  0.19499002] | [0.57807477 0.60191743 0.61579665] | [0.05782537 0.04088184 0.03295041] | [0.59032755 0.6925782  0.75008373] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 103.0509s, training loss at epoch 41: 129.6548
using time 108.2358s, training loss at epoch 42: 129.4336
using time 100.1859s, training loss at epoch 43: 129.0914
using time 103.3579s, training loss at epoch 44: 128.8833
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   45  | 103.57679843902588 | 52.567402839660645 | 128.58792114257812 | [0.1852902  0.25944946 0.3110759 ] | [0.15592585 0.17928259 0.19469576] | [0.58071452 0.6039989  0.61746768] | [0.05775672 0.04085756 0.0329024 ] | [0.58955724 0.69241074 0.75028468] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 103.2754s, training loss at epoch 46: 128.4244
using time 106.3829s, training loss at epoch 47: 128.1471
using time 103.9994s, training loss at epoch 48: 127.9587
using time 104.0805s, training loss at epoch 49: 127.7284
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   50  | 103.49316096305847 | 49.64545392990112 | 127.53987121582031 | [0.18504959 0.2592796  0.31057824] | [0.15534915 0.17875075 0.19406823] | [0.58258639 0.60532712 0.6185086 ] | [0.05762442 0.04079392 0.03283096] | [0.58882042 0.69251122 0.74927992] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 103.9060s, training loss at epoch 51: 127.3463
using time 103.6458s, training loss at epoch 52: 127.1801
using time 99.4357s, training loss at epoch 53: 127.0675
using time 99.6150s, training loss at epoch 54: 126.8347
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   55  | 99.62841963768005 | 48.780463218688965 | 126.6780776977539 | [0.18486987 0.25853916 0.30997038] | [0.15485055 0.17806517 0.19342594] | [0.58430549 0.6064843  0.61931375] | [0.05756414 0.04068508 0.03277123] | [0.58845201 0.69160694 0.74800723] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.1848698679159108
early stopping at 55, recall@20:0.1855
