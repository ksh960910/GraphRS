nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 2 --context_hops 3 --pool mean --ns mixgcf --n_negs 128 --K 1 &
cl loss에서 l* layer의 perturb되지 않은 emb + l* layer의 perturb된 emb 에다가 alpha가 무조건 0.5 이하가 되게끔 했을때의 실험결과

reading train and test user-item set ...
building the adj mat ...
loading over ...
X Mix Simple GCL model setup
start training ...
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 217.15163278579712 | 52.15637707710266 | 702.8851318359375 | [0.14385881 0.20315851 0.24458585] | [0.11690487 0.13599851 0.14836726] | [0.62947666 0.65066717 0.66266475] | [0.04343727 0.03106454 0.02511666] | [0.47354143 0.57371559 0.62874272] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 226.1662s, training loss at epoch 1: 640.1275
using time 216.7204s, training loss at epoch 2: 614.2097
using time 216.3033s, training loss at epoch 3: 590.6312
using time 213.1427s, training loss at epoch 4: 565.4562
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 213.91795253753662 | 50.44914150238037 | 539.1021728515625 | [0.16936911 0.23692697 0.28485256] | [0.14122709 0.16267605 0.17701436] | [0.58545689 0.6108969  0.62588492] | [0.05210999 0.03687621 0.02981613] | [0.54846272 0.64887132 0.70510416] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 216.0759s, training loss at epoch 6: 513.1848
using time 216.3372s, training loss at epoch 7: 489.3337
using time 213.4494s, training loss at epoch 8: 469.3913
using time 213.5910s, training loss at epoch 9: 453.6939
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |  tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 213.53464007377625 | 52.8521032333374 | 441.4115295410156 | [0.18360997 0.25658034 0.30725112] | [0.15539983 0.17838868 0.19352902] | [0.57297103 0.59845916 0.61338608] | [0.05717396 0.04044561 0.03254181] | [0.58557171 0.68876013 0.74251457] |
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 226.0438s, training loss at epoch 11: 431.4627
using time 215.0231s, training loss at epoch 12: 423.7271
using time 214.7059s, training loss at epoch 13: 417.0288
using time 224.6345s, training loss at epoch 14: 411.7635
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 217.0988063812256 | 53.867910623550415 | 407.18438720703125 | [0.1858283  0.26016192 0.31036911] | [0.15711682 0.18053583 0.19549022] | [0.5788645  0.60314517 0.61717347] | [0.05787729 0.04094715 0.03280639] | [0.58865296 0.69231027 0.74626566] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 218.6652s, training loss at epoch 16: 403.1848
using time 215.0757s, training loss at epoch 17: 399.8759
using time 213.1317s, training loss at epoch 18: 396.8764
using time 213.9761s, training loss at epoch 19: 394.4990
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 218.13789892196655 | 66.70840311050415 | 392.1346130371094 | [0.18535846 0.25875507 0.30871624] | [0.15650512 0.17969382 0.19462929] | [0.58290249 0.60599908 0.61912654] | [0.05762777 0.04071438 0.03264061] | [0.58791614 0.68999933 0.74415567] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 218.9902s, training loss at epoch 21: 390.2568
using time 205.1410s, training loss at epoch 22: 388.4770
using time 210.7412s, training loss at epoch 23: 386.9757
using time 211.0509s, training loss at epoch 24: 385.3745
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 222.57334232330322 | 60.71546292304993 | 384.1549987792969 | [0.18407472 0.25659827 0.30514156] | [0.15514948 0.17806542 0.19260557] | [0.58619463 0.60810017 0.62032618] | [0.05722085 0.04035769 0.03229843] | [0.58604059 0.6864157  0.74057204] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 224.1288s, training loss at epoch 26: 382.8982
using time 212.2733s, training loss at epoch 27: 381.8257
using time 209.4319s, training loss at epoch 28: 380.8473
using time 212.0362s, training loss at epoch 29: 379.8788
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss      |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 212.29630947113037 | 55.61545181274414 | 379.03662109375 | [0.18175824 0.25273961 0.30066064] | [0.1531172  0.17558701 0.18993687] | [0.58787532 0.60869007 0.6201662 ] | [0.05650077 0.03980173 0.03184909] | [0.58054793 0.68139192 0.7358162 ] |
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.18175824478811203
early stopping at 30, recall@20:0.1858
