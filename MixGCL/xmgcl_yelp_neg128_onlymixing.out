nohup python main.py --dataset yelp2018 --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 3 --context_hops 3 --pool mean --ns mixgcf --n_negs 128 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
X Mix Simple GCL model setup
start training ...
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 359.91437458992004 | 66.15934634208679 | 899.7964477539062 | [0.06419943 0.10487768 0.13699045] | [0.05278855 0.06811975 0.07936374] | [0.55985447 0.57530784 0.5853412 ] | [0.02879879 0.02370058 0.02080018] | [0.38729948 0.52721991 0.60834281] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 346.9397s, training loss at epoch 1: 800.7874
using time 375.8414s, training loss at epoch 2: 769.0623
using time 337.4381s, training loss at epoch 3: 746.4841
using time 367.7216s, training loss at epoch 4: 724.3628
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 341.3705241680145 | 60.156089544296265 | 698.4086303710938 | [0.06898551 0.11252593 0.14673621] | [0.05686158 0.07324855 0.08522186] | [0.5423814  0.55829753 0.56869432] | [0.03090659 0.02542551 0.02228169] | [0.40971959 0.5543135  0.63559429] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 351.0684s, training loss at epoch 6: 665.2489
using time 334.3305s, training loss at epoch 7: 626.5100
using time 349.8170s, training loss at epoch 8: 586.4088
using time 350.6720s, training loss at epoch 9: 551.4811
+-------+-------------------+-------------------+--------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |     Loss     |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 329.9923167228699 | 51.65010452270508 | 524.95703125 | [0.07201402 0.11846701 0.15434351] | [0.05937595 0.07684834 0.08937446] | [0.51792754 0.53420801 0.54472718] | [0.03237811 0.02682755 0.02345849] | [0.42544524 0.57625995 0.65959328] |
+-------+-------------------+-------------------+--------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 331.3825s, training loss at epoch 11: 504.5331
using time 339.3715s, training loss at epoch 12: 488.9048
using time 325.8875s, training loss at epoch 13: 476.5507
using time 320.3046s, training loss at epoch 14: 466.7656
+-------+--------------------+------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |  tesing time(s)  |       Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 318.24403405189514 | 55.1385977268219 | 458.881591796875 | [0.07255881 0.11913088 0.15503365] | [0.05976042 0.07729958 0.08983756] | [0.52235956 0.53813763 0.54827841] | [0.03255179 0.02698465 0.02358374] | [0.42793988 0.57919667 0.66114058] |
+-------+--------------------+------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 323.1817s, training loss at epoch 16: 452.0820
using time 332.2199s, training loss at epoch 17: 445.9857
using time 323.1344s, training loss at epoch 18: 441.0005
using time 311.5622s, training loss at epoch 19: 436.6397
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 316.6154501438141 | 50.637792110443115 | 432.47076416015625 | [0.07214724 0.11853823 0.15369526] | [0.05944593 0.07692685 0.08923282] | [0.52472111 0.54004181 0.54986706] | [0.03231969 0.02682598 0.02339849] | [0.42519262 0.57673361 0.65804598] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 312.5170s, training loss at epoch 21: 428.9970
using time 312.4041s, training loss at epoch 22: 426.0395
using time 326.3248s, training loss at epoch 23: 423.1944
using time 312.8438s, training loss at epoch 24: 420.6231
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 325.28614473342896 | 53.42313194274902 | 418.1063232421875 | [0.0718825  0.11749901 0.15203499] | [0.05921462 0.07639922 0.08851277] | [0.52576807 0.54074871 0.55027232] | [0.0321997  0.0266152  0.02319481] | [0.4239611  0.5729443  0.65488822] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 320.9918s, training loss at epoch 26: 415.9285
using time 328.0158s, training loss at epoch 27: 413.9487
using time 323.1886s, training loss at epoch 28: 411.8333
using time 310.6517s, training loss at epoch 29: 410.1118
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 320.38292169570923 | 48.845638275146484 | 408.3108825683594 | [0.07116781 0.11613466 0.15006194] | [0.05872542 0.07566708 0.0875738 ] | [0.52630548 0.54088141 0.55015931] | [0.03192181 0.02633415 0.02293009] | [0.42181382 0.56918656 0.65049893] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.07116780584479014
early stopping at 30, recall@20:0.0726
