nohup python main.py --dataset gowalla --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 2 --context_hops 3 --pool mean --ns mixgcf --n_negs 64 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
X Mix Simple GCL model setup
start training ...
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 126.51244306564331 | 69.15671920776367 | 587.7512817382812 | [0.14942991 0.21178544 0.25516497] | [0.12252362 0.14242207 0.15539463] | [0.61665283 0.63850728 0.65118485] | [0.04641135 0.03325574 0.02689899] | [0.49849287 0.59906893 0.65493335] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 128.0079s, training loss at epoch 1: 523.1221
using time 129.2849s, training loss at epoch 2: 497.0920
using time 132.0360s, training loss at epoch 3: 476.1371
using time 132.7098s, training loss at epoch 4: 455.3861
+-------+--------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |      Loss      |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 140.21288228034973 | 75.62465453147888 | 433.0830078125 | [0.16693174 0.23416256 0.28045833] | [0.13858075 0.15995409 0.17379399] | [0.59231302 0.61629189 0.63046899] | [0.05152388 0.03653627 0.02942316] | [0.5415634  0.64341215 0.69763547] |
+-------+--------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 130.4518s, training loss at epoch 6: 409.4948
using time 131.0055s, training loss at epoch 7: 386.5729
using time 128.8685s, training loss at epoch 8: 365.6853
using time 130.9620s, training loss at epoch 9: 347.1552
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 129.85693168640137 | 60.744489908218384 | 332.1105041503906 | [0.18149062 0.25355425 0.30493169] | [0.15330387 0.17607581 0.19141398] | [0.57430597 0.59956144 0.61439442] | [0.05644551 0.03997756 0.03227778] | [0.57934222 0.6826981  0.74013665] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 140.1821s, training loss at epoch 11: 320.0963
using time 129.3835s, training loss at epoch 12: 310.0273
using time 130.8368s, training loss at epoch 13: 301.9081
using time 143.4804s, training loss at epoch 14: 295.0383
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 134.143958568573 | 52.41778254508972 | 289.0466003417969 | [0.18493437 0.25782637 0.30909493] | [0.1561755  0.17916164 0.19449876] | [0.57985414 0.60407543 0.61827649] | [0.05754739 0.04062479 0.03273662] | [0.5847679  0.68872664 0.74512693] |
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 130.0271s, training loss at epoch 16: 284.1909
using time 137.3536s, training loss at epoch 17: 279.9288
using time 135.4018s, training loss at epoch 18: 276.2129
using time 130.0470s, training loss at epoch 19: 273.0533
+-------+-------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |       Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 131.3522756099701 | 50.64920210838318 | 270.211181640625 | [0.18584507 0.2592195  0.3095102 ] | [0.1566092  0.17970276 0.19478903] | [0.58416322 0.6073723  0.62084351] | [0.05782872 0.04076546 0.03277737] | [0.58892089 0.69040123 0.74579677] |
+-------+-------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 129.7920s, training loss at epoch 21: 267.6547
using time 129.3609s, training loss at epoch 22: 265.5309
using time 130.4505s, training loss at epoch 23: 263.5612
using time 132.3036s, training loss at epoch 24: 261.7624
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 118.67425012588501 | 50.31588006019592 | 260.2353210449219 | [0.18516858 0.25771599 0.30718639] | [0.15551541 0.17837522 0.19318715] | [0.58776667 0.60992582 0.62265459] | [0.05759763 0.04054776 0.03253846] | [0.58570567 0.68755442 0.74177775] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 118.4710s, training loss at epoch 26: 258.6835
using time 122.0291s, training loss at epoch 27: 257.3874
using time 118.5354s, training loss at epoch 28: 256.1053
using time 118.0727s, training loss at epoch 29: 254.9533
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 118.85106325149536 | 74.39343690872192 | 253.9401397705078 | [0.1835426  0.2552087  0.30361154] | [0.15399587 0.17662327 0.19109454] | [0.59034816 0.61152286 0.62354315] | [0.05711032 0.04025387 0.03219963] | [0.58208855 0.68336794 0.73799317] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 118.3719s, training loss at epoch 31: 253.0582
using time 118.2786s, training loss at epoch 32: 252.1871
using time 129.8690s, training loss at epoch 33: 251.2079
using time 118.1347s, training loss at epoch 34: 250.5183
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 118.24410820007324 | 55.466503858566284 | 249.71031188964844 | [0.18106046 0.25197213 0.29941486] | [0.15208389 0.17449373 0.18870169] | [0.59268993 0.61290157 0.62434133] | [0.05643546 0.03980424 0.03182285] | [0.5769643  0.67814321 0.73303637] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.18106045868224122
early stopping at 35, recall@20:0.1858
