nohup python main.py --dataset yelp2018 --gnn xmgcl --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 2 --context_hops 3 --pool mean --ns mixgcf --n_negs 128 --K 1 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
X Mix Simple GCL model setup
start training ...
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 336.9021747112274 | 60.35997533798218 | 1078.2076416015625 | [0.06153459 0.10057624 0.13143719] | [0.05078709 0.06547674 0.07627083] | [0.56699188 0.58281036 0.593074  ] | [0.02759726 0.02268931 0.01990443] | [0.37296324 0.50824176 0.58822786] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 330.6886s, training loss at epoch 1: 981.8684
using time 324.1048s, training loss at epoch 2: 951.0632
using time 332.0467s, training loss at epoch 3: 925.8778
using time 336.4878s, training loss at epoch 4: 897.4681
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 328.3666453361511 | 55.655221700668335 | 861.1390380859375 | [0.07006783 0.11411019 0.14880623] | [0.0577175  0.07428394 0.08641478] | [0.53154487 0.54822225 0.55907002] | [0.03146078 0.02583286 0.0226201 ] | [0.41414046 0.56145004 0.64247821] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 345.5799s, training loss at epoch 6: 817.4626
using time 352.8795s, training loss at epoch 7: 772.5405
using time 342.7410s, training loss at epoch 8: 735.4746
using time 344.3734s, training loss at epoch 9: 708.5309
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 351.05851888656616 | 70.63208937644958 | 688.8181762695312 | [0.0727267  0.11905616 0.15499641] | [0.05969699 0.07710512 0.08964266] | [0.51767249 0.53384182 0.54424042] | [0.03265915 0.02694913 0.02354585] | [0.42923456 0.57853354 0.66177214] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 337.3299s, training loss at epoch 11: 673.8796
using time 359.7642s, training loss at epoch 12: 662.3086
using time 346.5135s, training loss at epoch 13: 652.8773
using time 340.7663s, training loss at epoch 14: 645.3781
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 345.0999524593353 | 74.59145426750183 | 639.3073120117188 | [0.0724009  0.11956542 0.15519758] | [0.05969369 0.07742143 0.08989544] | [0.52222956 0.5378506  0.54792758] | [0.032506   0.0270107  0.02360164] | [0.42610837 0.57963875 0.66110901] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 343.0590s, training loss at epoch 16: 633.7596
using time 331.0725s, training loss at epoch 17: 629.0302
using time 339.4460s, training loss at epoch 18: 624.9665
using time 349.1522s, training loss at epoch 19: 621.3911
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 343.6045277118683 | 62.59423565864563 | 618.0934448242188 | [0.07192227 0.1187571  0.153884  ] | [0.05930485 0.07690653 0.08921031] | [0.52423362 0.53948904 0.54922398] | [0.03231653 0.02683861 0.02342007] | [0.4239611  0.57723885 0.65845649] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 337.8172s, training loss at epoch 21: 615.1516
using time 342.1081s, training loss at epoch 22: 612.6762
using time 344.0029s, training loss at epoch 23: 610.3804
using time 343.1640s, training loss at epoch 24: 608.1495
+-------+--------------------+------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |  tesing time(s)  |       Loss      |               recall               |                ndcg                |              novelty               |             precision              |             hit_ratio              |
+-------+--------------------+------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 338.33814883232117 | 66.5467357635498 | 606.04736328125 | [0.07178156 0.1175032  0.15201168] | [0.05919192 0.07633555 0.08844874] | [0.52518333 0.54007256 0.549557  ] | [0.03224706 0.02658441 0.02317745] | [0.42342428 0.57398636 0.65362511] |
+-------+--------------------+------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 3 log:0.07178155839391731
early stopping at 25, recall@20:0.0727
