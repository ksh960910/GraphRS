reading train and test user-item set ...
building the adj mat ...
loading over ...
Method 2 GCL model setup
start training ...
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss      |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 262.30689239501953 | 405.3506326675415 | 931.43115234375 | [0.0252556  0.03569663 0.0432148 ] | [0.01188738 0.01409585 0.01547684] | [0.00145204 0.00103691 0.00084182] | [0.02863923 0.04075359 0.0494213 ] |
|   0   | 262.30689239501953 | 363.1368668079376 | 931.43115234375 | [0.03364252 0.04718726 0.05680195] | [0.01651568 0.01939021 0.02115466] | [0.00190659 0.00135431 0.00109419] | [0.03766702 0.05326642 0.06428842] |
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 321.2796s, training loss at epoch 1: 876.5127
using time 347.0840s, training loss at epoch 2: 840.2730
using time 341.2344s, training loss at epoch 3: 776.3481
using time 343.0265s, training loss at epoch 4: 694.8864
+-------+--------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |      Loss      |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 344.59168553352356 | 422.6393258571625 | 625.7646484375 | [0.04400722 0.06412189 0.07877452] | [0.02065918 0.02490669 0.02759327] | [0.00251962 0.00185147 0.0015247 ] | [0.04970609 0.07250356 0.08917449] |
|   5   | 344.59168553352356 | 500.2912631034851 | 625.7646484375 | [0.05721195 0.08110455 0.09830434] | [0.0262415  0.03128488 0.03444551] | [0.00323806 0.00231903 0.00188834] | [0.06391025 0.09098071 0.11043269] |
+-------+--------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 327.8445s, training loss at epoch 6: 576.2355
using time 342.2720s, training loss at epoch 7: 541.5927
using time 342.5431s, training loss at epoch 8: 517.2938
using time 282.0251s, training loss at epoch 9: 499.6696
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 299.0037348270416 | 549.9107704162598 | 486.79022216796875 | [0.03957101 0.05740152 0.06986911] | [0.01836599 0.02212944 0.02441443] | [0.00224944 0.00165012 0.00134628] | [0.04447041 0.06488006 0.07909015] |
|   10  | 299.0037348270416 | 701.9970138072968 | 486.79022216796875 | [0.04994959 0.07114736 0.0868175 ] | [0.02316166 0.02764093 0.03051205] | [0.00282916 0.00203698 0.00166787] | [0.05588207 0.08002174 0.09783499] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 355.5836s, training loss at epoch 11: 477.1501
using time 360.9051s, training loss at epoch 12: 469.7445
using time 359.1601s, training loss at epoch 13: 463.9391
using time 360.7472s, training loss at epoch 14: 459.5158
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 348.69877648353577 | 576.6946017742157 | 455.98529052734375 | [0.03448844 0.05031082 0.06111483] | [0.0158223  0.01916499 0.02114479] | [0.00194859 0.00143853 0.00117261] | [0.03865055 0.0567235  0.06917376] |
|   15  | 348.69877648353577 | 328.0534086227417 | 455.98529052734375 | [0.04376773 0.06234503 0.07654068] | [0.0202711  0.02419629 0.02679545] | [0.00247306 0.00178645 0.00147052] | [0.04893325 0.07026818 0.08649786] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 2 log:0.04376772599485363
early stopping at 15, recall@20:0.0572
