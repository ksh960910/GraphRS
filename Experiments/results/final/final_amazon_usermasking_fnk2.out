reading train and test user-item set ...
building the adj mat ...
loading over ...
Method 2 GCL model setup
start training ...
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 266.0569429397583 | 425.3941445350647 | 938.7835083007812 | [0.02646067 0.03753068 0.04532909] | [0.01245155 0.01479729 0.01622826] | [0.00152324 0.00109004 0.00088162] | [0.03002665 0.04276169 0.0517434 ] |
|   0   | 266.0569429397583 | 354.4002377986908 | 938.7835083007812 | [0.03554348 0.049675   0.05982876] | [0.01716867 0.02015067 0.0220139 ] | [0.00201768 0.00142463 0.00115157] | [0.03981785 0.0559451  0.06755799] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 339.8527s, training loss at epoch 1: 875.7474
using time 342.5707s, training loss at epoch 2: 823.1508
using time 339.4528s, training loss at epoch 3: 741.5640
using time 332.2273s, training loss at epoch 4: 660.4417
+-------+------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)   |       Loss      |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 331.557984828949 | 453.79284501075745 | 599.94482421875 | [0.04428461 0.06420418 0.07854558] | [0.02063687 0.02483542 0.02746543] | [0.00253532 0.00185038 0.00151898] | [0.05002008 0.07251816 0.08886779] |
|   5   | 331.557984828949 | 464.7310485839844  | 599.94482421875 | [0.05659332 0.08091597 0.09841659] | [0.02611321 0.03124416 0.03444278] | [0.00320812 0.00231864 0.00188926] | [0.06329573 0.09081527 0.11043269] |
+-------+------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 339.7240s, training loss at epoch 6: 558.1592
using time 338.7547s, training loss at epoch 7: 528.9729
using time 329.9315s, training loss at epoch 8: 508.3481
using time 274.8600s, training loss at epoch 9: 493.2246
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 299.68019938468933 | 620.5972554683685 | 482.0805969238281 | [0.03930897 0.05682638 0.06929598] | [0.0182276  0.02192804 0.02420906] | [0.00223484 0.00163222 0.00133229] | [0.04420023 0.06418635 0.0782869 ] |
|   10  | 299.68019938468933 | 613.9762477874756 | 482.0805969238281 | [0.04932991 0.07061728 0.08604913] | [0.0229449  0.0274495  0.03027952] | [0.00279174 0.00202221 0.00165277] | [0.05516513 0.07938359 0.0968817 ] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 360.1887s, training loss at epoch 11: 473.6930
using time 355.5012s, training loss at epoch 12: 467.1397
using time 349.4756s, training loss at epoch 13: 462.0015
using time 358.7128s, training loss at epoch 14: 458.0627
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 346.49180030822754 | 564.2590606212616 | 454.86651611328125 | [0.0346484  0.04981043 0.06090203] | [0.01576075 0.01895938 0.02099273] | [0.0019548  0.00142265 0.00116738] | [0.03878199 0.05616853 0.06894739] |
|   15  | 346.49180030822754 | 333.2667441368103 | 454.86651611328125 | [0.04324801 0.06263567 0.07631169] | [0.02012255 0.02421614 0.02671792] | [0.00244745 0.00179531 0.00146566] | [0.04839752 0.07060696 0.08611181] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 2 log:0.04324800544030049
early stopping at 15, recall@20:0.0566
