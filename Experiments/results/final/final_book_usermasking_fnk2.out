nohup python main.py --dataset amazon-book --gnn m2 --dim 64 --lr 0.001 --batch_size 2048 --gpu_id 3 --context_hops 3 --pool mean --ns mixgcf --K 1 --fnk 2 --eps 0.15 &
reading train and test user-item set ...
building the adj mat ...
loading over ...
Method 2 GCL model setup
start training ...
+-------+--------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |       Loss      |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 407.87697100639343 | 159.68028092384338 | 1641.6513671875 | [0.03326079 0.05311743 0.06928626] | [0.02673427 0.03422276 0.03984555] | [0.01355364 0.01108589 0.0098175 ] | [0.17483235 0.25549498 0.31391174] |
+-------+--------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 410.9786s, training loss at epoch 1: 1492.0177
using time 407.1407s, training loss at epoch 2: 1322.5223
using time 409.0148s, training loss at epoch 3: 1138.5002
using time 408.2569s, training loss at epoch 4: 1039.7986
+-------+------------------+-------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)  |      Loss     |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+-------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 406.153431892395 | 166.7881100177765 | 988.306640625 | [0.04731234 0.07677778 0.10153195] | [0.03716106 0.04827867 0.05684841] | [0.01985125 0.01653289 0.01477295] | [0.26681738 0.38484774 0.46366762] |
+-------+------------------+-------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 407.5699s, training loss at epoch 6: 956.4033
using time 406.0608s, training loss at epoch 7: 934.4279
using time 406.8461s, training loss at epoch 8: 917.4491
using time 405.7096s, training loss at epoch 9: 904.2358
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 404.36225962638855 | 162.66526556015015 | 893.7006225585938 | [0.04860266 0.0788576  0.10342198] | [0.03799828 0.04942258 0.05796453] | [0.02019795 0.01683305 0.01497052] | [0.27225061 0.39267463 0.47348924] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 403.8454s, training loss at epoch 11: 884.5905
using time 409.3127s, training loss at epoch 12: 876.7546
using time 407.2229s, training loss at epoch 13: 870.2463
using time 404.1629s, training loss at epoch 14: 864.2505
+-------+-------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |       Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 404.5418977737427 | 195.79198837280273 | 859.201416015625 | [0.04855777 0.07921525 0.10318629] | [0.03798046 0.04955018 0.05788446] | [0.02011151 0.01681453 0.01487142] | [0.27276354 0.3950303  0.47546496] |
+-------+-------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 408.0795s, training loss at epoch 16: 854.0883
using time 406.9001s, training loss at epoch 17: 850.0333
using time 406.3867s, training loss at epoch 18: 846.1011
using time 408.5117s, training loss at epoch 19: 842.6404
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 409.32720613479614 | 199.0409529209137 | 839.3865356445312 | [0.04817335 0.07876526 0.1022257 ] | [0.03761946 0.04920161 0.05735364] | [0.0198693  0.01667917 0.01470393] | [0.2723646  0.39560022 0.47442011] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 424.9195s, training loss at epoch 21: 836.4020
using time 408.1232s, training loss at epoch 22: 833.5865
using time 407.6524s, training loss at epoch 23: 831.0502
using time 409.0388s, training loss at epoch 24: 828.5199
+-------+-------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |       Loss      |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 407.4484043121338 | 215.90389013290405 | 826.31689453125 | [0.04773181 0.07767462 0.10078009] | [0.03723553 0.04856744 0.05661338] | [0.01963278 0.01640134 0.01448356] | [0.27040787 0.39252265 0.47119056] |
+-------+-------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
using time 418.2266s, training loss at epoch 26: 824.1721
using time 405.9110s, training loss at epoch 27: 822.1159
using time 409.1337s, training loss at epoch 28: 820.1807
using time 405.5220s, training loss at epoch 29: 818.5427
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 407.2605891227722 | 214.1053285598755 | 816.8482055664062 | [0.04717435 0.07655394 0.09909215] | [0.03675419 0.04785598 0.05569898] | [0.01938107 0.01614725 0.01421886] | [0.26856513 0.38944509 0.46655522] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 4 log:0.04717434765530532
early stopping at 30, recall@20:0.0486
